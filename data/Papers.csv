Document Title,Coding,Categories,Authors,,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier,,
Churn-resilient task scheduling in a tiered IoT infrastructure,"Rigid time constraints, tiered, low-latency, coverage and accessibility, mobility support, heterogeneity","12, 9, 4, 13, 8,",J. Fan; X. Wei; T. Wang; T. Lan; S. Subramaniam,,China Communications,30 Aug 2019,2019,16,8,162,175,"Cloud-as-the-center computing paradigms face multiple challenges in the 5G and Internet of Things scenarios, where the service requests are usually initiated by the end-user devices located at network edge and have rigid time constraints. Therefore, Fog computing, or mobile edge computing, is introduced as a promising solution to the service provision in the tiered IoT infrastructure to compensate the shortage of traditional cloud-only architecture. In this cloud-to-things continuum, several cloudlet or mobile edge server entities are placed at the access network to handle the task offloading and processing problems at the network edge. This raises the resource scheduling problem in this tiered system, which is vital for the promotion of the system efficiency. Therefore, in this paper, a scheduling mechanism for the cloudlets or fog nodes are presented, which takes the mobile tasks' deadline and resources requirements at the same time while promoting the overall profit of the system. First, the problem at the cloudlet, to which IoT devices offload their tasks, is formulated as a multi-dimensional 0-1 knapsack problem. Second, based on ant colony optimization, a scheduling algorithm is presented which treat this problem as a subset selection problem. Third, to promote the performance of the system in the dynamic environments, a churn-refined algorithm is further put forward. A series of simulation experiments have shown that out proposal outperforms many state-of-the-art algorithms in both profit and guarantee ratio.",1673-5447,,10.23919/JCC.2019.08.014,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820768,fog computing;task scheduling;deadline constrained;internet of things;ant colony optimization,Task analysis;Cloud computing;Heuristic algorithms;Internet of Things;Job shop scheduling;Edge computing;Scheduling algorithms,ant colony optimisation;cloud computing;Internet of Things;knapsack problems;mobile computing;resource allocation;scheduling,churn-resilient task scheduling;tiered IoT infrastructure;cloud-as-the-center computing paradigms;service requests;end-user devices;mobile edge computing;mobile edge server entities;resource scheduling problem;fog nodes;IoT devices;multidimensional 0-1 knapsack problem;subset selection problem;churn-refined algorithm;5G Internet of Things scenarios;cloud-to-things;fog computing;cloud-only architecture;ant colony optimization,,2,,,,30 Aug 2019,,,IEEE,IEEE Magazines,,
"Fog/Edge Computing-Based IoT (FECIoT): Architecture, Applications, and Research Issues","Security, scalability, openness, reliability, hierarchical organization, autonomy, programmability","15, 4, 28, 16, 9, 1, 29,",B. Omoniwa; R. Hussain; M. A. Javed; S. H. Bouk; S. A. Malik,,IEEE Internet of Things Journal,18 Jun 2019,2019,6,3,4118,4149,"The Internet-of-Things (IoT) is the future of the Internet, where everything will be connected. Studies have revealed that fog/edge computing-based services will play a major role in extending the cloud by carrying out intermediary services at the edge of the network. Fog/edge computing-based IoT's (FECIoT) distributed architecture enhances service provisioning along the Cloud-to-Things continuum, thereby making it suitable for mission-critical applications. Furthermore, the proximity of fog/edge devices to where the data is produced makes it stand-out in terms of resource allocation, service delivery, and privacy. From the business perspective, FECIoT will lead to a boom and spring up of small-to-medium-sized enterprises, thereby encouraging inclusion for all. To this end, we present a comprehensive survey on state-of-the-art IoT literature over the period 2008-2018 and propose the FECIoT framework which covers the enabling technologies, services, and open research issues. A tutorial approach is employed, progressing from basic to more advanced concepts within the IoT domain. Lastly, we show how FECIoT can be deployed in real-life cyber-physical systems, such as the intelligent transportation system, smart grid, smart health-care, smart homes, and smart environment.",2327-4662,,10.1109/JIOT.2018.2875544,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489908,Cyber-physical systems (CPSs);enabling technologies;fog/edge computing (FEC);Internet-of-Things (IoT);service-oriented architecture (SoA),Cloud computing;Protocols;Computational modeling;Computer architecture;Security;Privacy;Internet of Things,cloud computing;cyber-physical systems;data privacy;Internet of Things;resource allocation;software architecture,real-life cyber-physical systems;edge devices;edge computing-based IoT distributed architecture;fog computing-based IoT distributed architecture;edge computing-based services;fog computing-based services;IoT literature;fog devices;cloud-to-things continuum;IoT domain;FECIoT framework;service delivery;mission-critical applications;intermediary services;Internet-of-Things,,102,,181,IEEE,11 Oct 2018,,,IEEE,IEEE Journals,,
From Cloud Down to Things: An Overview of Machine Learning in Internet of Things,"hierarchicall architecture, connectedness, intelligent devices, computation distributed across layers","9, 4, 2, 21,",F. Samie; L. Bauer; J. Henkel,,IEEE Internet of Things Journal,18 Jun 2019,2019,6,3,4921,4934,"With the numerous Internet of Things (IoT) devices, the cloud-centric data processing fails to meet the requirement of all IoT applications. The limited computation and communication capacity of the cloud necessitate the edge computing, i.e., starting the IoT data processing at the edge and transforming the connected devices to intelligent devices. Machine learning (ML) the key means for information inference, should extend to the cloud-to-things continuum too. This paper reviews the role of ML in IoT from the cloud down to embedded devices. Different usages of ML for application data processing and management tasks are studied. The state-of-the-art usages of ML in IoT are categorized according to their application domain, input data type, exploited ML techniques, and where they belong in the cloud-to-things continuum. The challenges and research trends toward efficient ML on the IoT edge are discussed. Moreover, the publications on the “ML in IoT” are retrieved and analyzed systematically using ML classification techniques. Then, the growing topics and application domains are identified.",2327-4662,,10.1109/JIOT.2019.2893866,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616889,Edge computing;embedded intelligence;embedded systems;Internet of Things (IoT);machine learning (ML),Internet of Things;Machine learning;Cloud computing;Predictive models;Data processing;Vegetation;Computer architecture,cloud computing;Internet of Things;learning (artificial intelligence),input data type;cloud-to-things continuum;IoT edge;ML classification techniques;machine learning;cloud-centric data processing;IoT applications;edge computing;IoT data processing;connected devices;intelligent devices;application data processing;ML techniques;Internet of Things devices,,85,,83,IEEE,17 Jan 2019,,,IEEE,IEEE Journals,,
Decentralized Edge-to-Cloud Load Balancing: Service Placement for the Internet of Things,"Scalability, low latency, heterogeneity, service placement challenges, collective learning, privacy and security constraints","4, 12, 8, 5, 6, 15,",Z. Nezami; K. Zamanifar; K. Djemame; E. Pournaras,,IEEE Access,3 May 2021,2021,9,,64983,65000,"The Internet of Things (IoT) requires a new processing paradigm that inherits the scalability of the cloud while minimizing network latency using resources closer to the network edge. On the one hand, building up such flexibility within the edge-to-cloud continuum consisting of a distributed networked ecosystem of heterogeneous computing resources is challenging. On the other hand, IoT traffic dynamics and the rising demand for low-latency services foster the need for minimizing the response time and a balanced service placement. Load-balancing for fog computing becomes a cornerstone for cost-effective system management and operations. This paper studies two optimization objectives and formulates a decentralized load-balancing problem for IoT service placement: (global) IoT workload balance and (local) quality of service (QoS), in terms of minimizing the cost of deadline violation, service deployment, and unhosted services. The proposed solution, EPOS Fog, introduces a decentralized multi-agent system for collective learning that utilizes edge-to-cloud nodes to jointly balance the input workload across the network and minimize the costs involved in service execution. The agents locally generate possible assignments of requests to resources and then cooperatively select an assignment such that their combination maximizes edge utilization while minimizes service execution cost. Extensive experimental evaluation with realistic Google cluster workloads on various networks demonstrates the superior performance of EPOS Fog in terms of workload balance and QoS, compared to approaches such as First Fit and exclusively Cloud-based. The results confirm that EPOS Fog reduces service execution delay up to 25% and the load-balance of network nodes up to 90%. The findings also demonstrate how distributed computational resources on the edge can be utilized more cost-effectively by harvesting collective intelligence.",2169-3536,,10.1109/ACCESS.2021.3074962,"Government Ministry of Science, Research and Technology of the Islamic Republic of Iran; Swiss Federal Institute of Technology in Lausanne (EPFL); Swiss Federal Institute of Technology (ETH) in Zürich; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418552,Agent;cloud computing;collective learning;distributed optimization;edge computing;fog computing;Internet of Things (IoT);load-balancing;service placement,Internet of Things;Cloud computing;Edge computing;Quality of service;Delays;Servers;Computer architecture,cloud computing;computer centres;Internet of Things;multi-agent systems;optimisation;power aware computing;quality of service;resource allocation,edge utilization;minimizes service execution cost;realistic Google cluster workloads;EPOS Fog;workload balance;service execution delay;load-balance;distributed computational resources;cost-effectively;decentralized edge-to-Cloud load balancing;processing paradigm;network edge;edge-to-cloud continuum;distributed networked ecosystem;heterogeneous computing resources;IoT traffic dynamics;low-latency services;balanced service placement;fog computing;cost-effective system management;optimization objectives;formulates;decentralized load-balancing problem;IoT service placement;service deployment;unhosted services;decentralized multiagent system;edge-to-cloud nodes;input workload,,9,,82,CCBY,28 Apr 2021,,,IEEE,IEEE Journals,,
Dependability and Security Quantification of an Internet of Medical Things Infrastructure Based on Cloud-Fog-Edge Continuum for Healthcare Monitoring Using Hierarchical Models,"Real-time support, latency-sensitive support, security challenges","12, 15, ",T. A. Nguyen; D. Min; E. Choi; J. -W. Lee,,IEEE Internet of Things Journal,25 Oct 2021,2021,8,21,15704,15748,"Rising aggressive virus pandemics urge to conduct studies on dependability and security of modern computing systems to secure autonomous and continuous operations of healthcare systems. In that regard, we propose to quantify dependability and security measures of an Internet-of-Medical Things (IoMT) infrastructure relied on an integrated physical architecture of cloud/fog/edge (CFE) computing paradigms in this article. We propose a reliability/availability quantification methodology for the IoMT infrastructure using a hierarchical model of three levels: 1) fault tree (FT) of overall IoMT infrastructure consisting of CFE member systems; 2) FT of subsystems within CFE member systems; and 3) continuous-time Markov chain (CTMC) models of components/devices in the subsystems. We incorporate a number of failure modes for the underlying subsystems, including Mandel-bug related failures and non-Mandel bugs related failure, as well as failures due to cyber-security attacks on software subsystems. Five case-studies of configuration alternation and four operational scenarios of the IoMT infrastructure are considered to comprehend the dependability characteristics of the IoMT physical infrastructure. The metrics of interest include reliability over time, steady state availability (SSA), sensitivity of SSA wrt. selected mean time to failure—equivalent (MTTFeq) and mean time to recovery—equivalent (MTTReq), and sensitivity of SSA wrt. frequencies of cyber-security attacks on software subsystems. The analysis results help comprehend operational behaviors and properties of a typical IoMT infrastructure. The findings of this study can improve the design and implementation of real-world IoMT infrastructures consisting of cloud, fog, and edge computing paradigms.",2327-4662,,10.1109/JIOT.2021.3081420,"Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:2020R1A6A1A03046811); NRF(grant numbers:NRF-2018R1D1A1B070467791); Korea government (MSIT); Korea Agency for Infrastructure Technology Advancement (KAIA) grant; Ministry of Land, Infrastructure and Transport(grant numbers:20CTAP-C152021-02); Ministry of Science and ICT (MSIT), South Korea, under the Information Technology Research Center (ITRC) Support Program; Institute for Information & Communications Technology Planning & Evaluation (IITP)(grant numbers:IITP-2020-2016-0-00465); “The Competency Development Program for Industry Specialist” of the Korean Ministry of Trade, Industry and Energy (MOTIE); Korea Institute for Advancement of Technology (KIAT)(grant numbers:N0002428); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9434376,Availability;cloud computing;cyber security attack;edge computing;e-health monitoring;fog computing;hierarchical model;Internet of Medical Things (IoMT);reliability,Security;Medical services;Reliability;Computational modeling;Monitoring;Cloud computing;Data models,cloud computing;fault trees;health care;Internet of Things;Markov processes;program debugging;security of data,cloud-fog-edge continuum;healthcare monitoring;hierarchical model;autonomous operations;healthcare systems;security measures;Internet-of-Medical Things infrastructure;integrated physical architecture;CFE member systems;continuous-time Markov chain models;failure modes;Mandel-bug related failures;nonMandel bugs related failure;cyber-security attacks;software subsystems;IoMT physical infrastructure;SSA wrt;IoMT infrastructure;edge computing paradigms;security quantification;fault tree;steady state availability;mean time to recovery-equivalent,,7,,84,IEEE,18 May 2021,,,IEEE,IEEE Journals,,
Virtual Fog: A Virtualization Enabled Fog Computing Framework for Internet of Things,"QoS-awareness, network function and seervice virtualization, heterogeneuity, ubiquity, inter-component collaboration","19, 22, 8, 4, 2,",J. Li; J. Jin; D. Yuan; H. Zhang,,IEEE Internet of Things Journal,9 Feb 2018,2018,5,1,121,131,"The prosperity of Internet of Things (IoT) and the success of rich Cloud services have expedited the emergence of a new computing paradigm called Fog computing, which promotes the processing of data at the proximity of their sources. Complementary to the Cloud, Fog promises to offer many appealing features, such as low latency, low cost, high multitenancy, high scalability, and to consolidate the IoT ecosystem. Although the Fog concept has been widely adopted in many areas, a comprehensive realization has yet been adequately researched. To address all these issues, in this paper, object virtualization is investigated to overcome obstacles resulting from resource constraints on sensory-level nodes while service virtualization is explored to easily create tailored applications for end users. Moreover, network function virtualization is studied to perform the flexibility of network service provisioning. Grounded on object virtualization, network function virtualization and service virtualization, a layered framework that encompasses smart objects, Fog and Cloud is presented to illustrate the realization of virtual Fog along IoT continuum. This proposed virtual Fog framework is applied to a smart living case for verification, then quantitative analysis is conducted to demonstrate the low latency, low operating expense, high multitenancy and scalability, followed by an experimental evaluation to further confirm that delay and jitter can be decreased through virtualization.",2327-4662,,10.1109/JIOT.2017.2774286,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113467,Fog computing;Internet of Things (IoT);network function virtualization;object virtualization;service virtualization,Virtualization;Cloud computing;Hardware;Internet of Things;Network function virtualization;Sensor phenomena and characterization,cloud computing;Internet of Things;virtualisation,virtualization enabled Fog computing framework;rich Cloud services;IoT ecosystem;object virtualization;service virtualization;network function virtualization;network service provisioning;IoT continuum;virtual Fog framework,,48,,24,IEEE,16 Nov 2017,,,IEEE,IEEE Journals,,
Keynote Speech 2: Extending the Data Science pipeline: Integrating Machine Learning into Edge Environments,"Edge intelligence, federated learning, privacy capacity & resilience constraints","6, 15, 16, ",O. F. Rana,,2021 Second International Conference on Intelligent Data Science Technologies and Applications (IDSTA),31 Dec 2021,2021,,,2,2,"Summary form only given, as follows. A record of the panel discussion was not made available for publication as part of the conference proceedings. Internet of Things (IoT) applications today involve data capture from sensors and devices that are close to the phenomenon being measured, with such data subsequently being transmitted to Cloud data centre for storage, analysis and visualisation. Currently devices used for data capture often differ from those that are used to subsequently carry out analysis on such data. Increasing availability of storage and processing devices closer to the data capture device, perhaps over a one-hop network connection or even directly connected to the IoT device itself, requires more efficient allocation of processing across such edge devices and data centres. Supporting machine learning & data analytics directly on edge devices also enables support for distributed (federated) learning, enabling user devices to be used directly in the inference or learning process. Scalability in this context needs to consider both cloud resources, data distribution and initial processing on edge resources closer to the user. This talk investigates how a data analytics pipeline can be deployed across the cloud-edge continuum. Understanding what should be executed at a data centre and what can be moved to an edge resource remains an important challenge -- especially with increasing capability of our edge devices. The following questions are addressed in this talk: How do we partition machine learning algorithms across Edge-Network-Cloud resources (often referred to as the ""Cloud-Edge Continuum"") based on constraints such as privacy, capacity and resilience? Can machine learning algorithms be adapted based on the characteristics of devices on which they are hosted? What does this mean for stability/ convergence vs. performance? Do we trade-off accuracy for “explainability” of results? Given a complex parameter space can “approximations” help with explaining the basis of results?",,978-1-6654-2180-5,10.1109/IDSTA53674.2021.9660813,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660813,,Cloud computing;Internet of Things;Data science;Data centers;Software;Pipelines;Performance evaluation,cloud computing;computer centres;data analysis;data visualisation;Internet of Things;learning (artificial intelligence);storage management,data science pipeline;Internet of Things device;data capture device;IoT device;edge devices;machine learning;distributed learning;data distribution;data analytics;cloud-edge continuum;cloud data centre;edge-network-cloud resources;data storage;data analysis;data visualization,,,,,IEEE,31 Dec 2021,,,IEEE,IEEE Conferences,,
"fogØ5: Unifying the computing, networking and storage fabrics end-to-end","Heterogeneity, resource constraints, failure resilience","17, 8, 16,",A. Corsaro; G. Baldoni,,2018 3rd Cloudification of the Internet of Things (CIoT),27 Jan 2019,2018,,,1,8,"Fog computing aims at providing horizontal, system-level, abstractions to distribute computing, storage, control and networking functions closer to the user along a cloud-to-thing continuum. Whilst fog computing is increasingly recognized as the key paradigm at the foundation of Consumer and Industrial Internet of Things (IoT), most of the initiatives on fog computing focus on extending cloud infrastructure. As a consequence, these infrastructure fall short in addressing heterogeneity and resource constraints characteristics of fog computing environments. In this paper, we (1) explain the requirements of fog computing infrastructure and how they extend well beyond those traditionally addressed by Cloud Computing infrastructures; (2) introduce fogØ5, a fog Infrastructure that unifies computing, networking and storage fabrics end-to-end, while addressing the challenges imposed by resource heterogeneity, (3) explain the novel architectural approach adopted by fogØ5 to have a server-less data-centric architecture that is scalable, secure, and highly resilient to failures, (4) demonstrate the use of fogØ5 in some real-world use cases and (5) conclude and reports on future works.",,978-1-5386-4629-8,10.1109/CIOT.2018.8627124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8627124,IloT;Fog Computing;Edge Computing;MEC;Internet of Things;cyber-physical systems;virtualisation;IoT infrastructure;fog05;fog computing platform;function virtualization;platform-as-a-service layer;Multi-Access Edge Computing,Edge computing;Cloud computing;Computer architecture;Internet of Things;Real-time systems;Databases;Servers,cloud computing;Internet of Things,storage fabrics end-to-end;IoT;Internet of Things;fog computing;fogØ5;fog infrastructure;cloud computing;cloud infrastructure;cloud-to-thing continuum;networking functions,,4,,12,,27 Jan 2019,,,IEEE,IEEE Conferences,,
Edge and Fog Computing Enabled AI for IoT-An Overview,"QoS constraints, Ubiquitous intelligence, heterogeneity, hierarchy, geographic distribution, collaborative computation","19, 6, 8, 9, 3, 2,",Z. Zou; Y. Jin; P. Nevalainen; Y. Huan; J. Heikkonen; T. Westerlund,,2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),25 Jul 2019,2019,,,51,56,"In recent years, Artificial Intelligence (AI) has been widely deployed in a variety of business sectors and industries, yielding numbers of revolutionary applications and services that are primarily driven by high-performance computation and storage facilities in the cloud. On the other hand, embedding intelligence into edge devices is highly demanded by emerging applications such as autonomous systems, human-machine interactions, and the Internet of Things (IoT). In these applications, it is advantageous to process data near or at the source of data to improve energy & spectrum efficiency and security, and decrease latency. Although the computation capability of edge devices has increased tremendously during the past decade, it is still challenging to perform sophisticated AI algorithms in these resource-constrained edge devices, which calls for not only low-power chips for energy efficient processing at the edge but also a system-level framework to distribute resources and tasks along the edge-cloud continuum. In this overview, we summarize dedicated edge hardware for machine learning from embedded applications to sub-mW “always-on” IoT nodes. Recent advances of circuits and systems incorporating joint design of architectures and algorithms will be reviewed. Fog computing paradigm that enables processing at the edge while still offering the possibility to interact with the cloud will be covered, with focus on opportunities and challenges of exploiting fog computing in AI as a bridge between the edge device and the cloud.",,978-1-5386-7884-8,10.1109/AICAS.2019.8771621,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8771621,Internet of Things;Artificial Intelligence;Edge AI;Machine Learning;Fog computing;Edge computing;Embedded Processor,Cloud computing;Edge computing;Artificial intelligence;Computer architecture;Hardware;Internet of Things;Computational modeling,cloud computing;embedded systems;Internet of Things;learning (artificial intelligence);parallel processing;power aware computing;resource allocation,business sectors;high-performance computation;autonomous systems;human-machine interactions;computation capability;resource-constrained edge devices;energy efficient processing;edge-cloud continuum;edge hardware;embedded applications;fog computing paradigm;IoT;artificial intelligence;low-power chips;machine learning,,18,,63,,25 Jul 2019,,,IEEE,IEEE Conferences,,
Methodical Analysis of a Fog Computing Assisted Animal-Welfare Software System in a Real-World Smart Dairy Farm IoT Deployment,"Efficient resource utilization, lower cost, fast service delivery, improved privacy protection","17, 20, 12, 15,",M. Taneja; N. Jalodia; P. Malone; E. Misha,,2021 IEEE 7th World Forum on Internet of Things (WF-IoT),9 Nov 2021,2021,,,857,864,"In the IoT era, the devices along the things-to-cloud continuum, present a unique opportunity to additionally serve as computing hubs. Termed Fog computing, this paradigm can be used to host applications and process data closer to the source. In this article, we present a methodical analysis of our fog enabled software system in an IoT enabled smart dairy farm. The developed software system uses locomotion data generated by wearables on cows’ feet to detect anomalies in their behaviour. We analyze the benefits of using a fog computing assisted approach for developing such IoT solutions. We use resource utilization as the performance metric for analyzing the benefits of leveraging the fog computing paradigm compared to the traditional cloud centric approach. The results suggest that a fog enabled software system brings benefits such as efficient utilization of computing resources, improved QoS etc. The evaluation indicates that there will be need of special design (including both low-level and high-level system design) re-configurations and also re-engineering of some components to provide higher scalability using less computational resources.",,978-1-6654-4431-6,10.1109/WF-IoT51360.2021.9595051,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9595051,Fog Computing;Methodical Analysis;Fog Enabled Software;Internet of Things (IoT);Smart Dairy Farming;Microservices,Measurement;Cloud computing;Wearable computers;Scalability;Quality of service;Software systems;Computational efficiency,cloud computing;dairying;Internet of Things;quality of service,animal-welfare software system;IoT;things-to-cloud continuum;computing hubs;locomotion data;high-level system design;fog computing;smart dairy farm;cloud centric approach,,,,30,IEEE,9 Nov 2021,,,IEEE,IEEE Conferences,,
TEMPOS: QoS Management Middleware for Edge Cloud Computing FaaS in the Internet of Things,"QoS management, heterogeneity, serverlessness, accessibility, low environmental impact","19, 8, 23, 4, 7,",A. Garbugli; A. Sabbioni; A. Corradi; P. Bellavista,,IEEE Access,12 May 2022,2022,10,,49114,49127,"Several classes of advanced Internet of Things (IoT) applications, e.g., in the industrial manufacturing domain, call for Quality of Service (QoS) management to guarantee/control performance indicators, even in presence of many sources of “stochastic noise” in real deployment environments, from scarcely available bandwidth in a time window to concurrent usage of virtualized processing resources. This paper proposes a novel IoT-oriented middleware that i) considers and coordinates together different aspects of QoS monitoring, control, and management for different kinds of virtualized resources (from networking to processing) in a holistic way, and ii) specifically targets deployment environments where edge cloud resources are employed to enable the Serverless paradigm in the cloud continuum. The reported experimental results show how it is possible to achieve the desired QoS differentiation by coordinating heterogeneous mechanisms and technologies already available in the market. This demonstrates the feasibility of effective QoS-aware management of virtualized resources in the cloud-to-things continuum when considering a Serverless provisioning scenario, which is completely original in the related literature to the best of our knowledge.",2169-3536,,10.1109/ACCESS.2022.3173434,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770777,Edge cloud computing;FaaS;Internet of Things;interoperability;middleware;QoS management;serverless,Quality of service;Cloud computing;FAA;Internet of Things;Middleware;Process control;Method of moments,cloud computing;Internet of Things;middleware;quality of service;resource allocation,serverless paradigm;cloud continuum;QoS differentiation;heterogeneous mechanisms;cloud-to-things continuum;TEMPOS;QoS management middleware;edge cloud computing FaaS;advanced Internet;industrial manufacturing domain;stochastic noise;deployment environments;scarcely available bandwidth;time window;concurrent usage;virtualized processing resources;QoS monitoring;Internet of Things;IoT-oriented middleware;quality of service management,,,,35,CCBY,9 May 2022,,,IEEE,IEEE Journals,,
On the Fog-Cloud Cooperation: How Fog Computing can address latency concerns of IoT applications,"Latency-sensitive support, layered architecture, scheduling challenges","12,9, 5, ",A. Karamoozian; A. Hafid; E. M. Aboulhamid,,2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC),15 Aug 2019,2019,,,166,172,"Fog computing emerged as a new computing paradigm which moves the computing power to the proximity of users, from core to the edge of the network. It is known as the extension of Cloud computing and it offers inordinate opportunities for real-time and latency-sensitive IoT applications. An IoT application consists of a set of dependent Processing Elements (PEs) defined as operations performed on data streams and can be modeled as a Directed Acyclic Graph (DAG). Each PE performs a variety of low-level computation on the incoming data such as aggregation or filtering. A key challenge is to decide how to distribute such PEs over the resources, in order to minimize the overall response time of the entire PE graph. This problem is known as distributed PE scheduling and placement problem. In this work, we try to address the question of how fog computing paradigm can help reducing the IoT application response time by efficiently distributing PE graphs over the Fog-Cloud continuum. We mathematically formulate the fundamental characteristics of IoT application and Fog infrastructure, then model the system as an optimization problem using Gravitational Search Algorithm (GSA) meta-heuristic technique. Our proposed GSA model is evaluated by comparing it with a well-known evolutionary algorithm in the literature via simulation. Also, a comparative analysis with the legacy cloud infrastructure is done in order to show the significant impact of fog presence on the performance of PE processing. Evaluation of our model demonstrates the efficiency of our approach comparing to the current literature.",,978-1-7281-1796-6,10.1109/FMEC.2019.8795320,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8795320,Internet of Things;IoT stream processing;Fog/Cloud Computing;Scheduling and Placement optimization,,cloud computing;directed graphs;evolutionary computation;Internet of Things;optimisation;search problems,latency-sensitive IoT applications;data streams;low-level computation;placement problem;fog computing paradigm;IoT application response time;fog-cloud cooperation;processing elements;directed acyclic graph;distributed PE scheduling;distributing PE graphs;optimization problem;gravitational search algorithm meta-heuristic technique;evolutionary algorithm,,8,,18,,15 Aug 2019,,,IEEE,IEEE Conferences,,
On the Deployment of IoT Systems: An Industrial Survey,"Heterogeneity, geographic distribution, dynamic deployment","8, 3, 5, ",F. Alkhabbas; R. Spalazzese; M. Cerioli; M. Leotta; G. Reggio,,2020 IEEE International Conference on Software Architecture Companion (ICSA-C),19 May 2020,2020,,,17,24,"Internet of Things (IoT) systems are complex and multifaceted, and the design of their architectures needs to consider many aspects at a time. Design decisions concern, for instance, the modeling of software components and their interconnections, as well as where to deploy the components within the available hardware infrastructure in the Edge-Cloud continuum. A relevant and challenging task, in this context, is to identify optimal deployment models due to all the different aspects involved, such as extra-functional requirements of the system, heterogeneity of the hardware resources concerning their processing and storage capabilities, and constraints like legal issues and operational cost limits. To gain insights about the deployment decisions concerning IoT systems in practice, and the factors that influence those decisions, we report about an industrial survey we conducted with 66 IoT architects from 18 countries across the world. Each participant filled in a questionnaire that comprises 15 questions. By analyzing the collected data, we have two main findings: (i) architects rely on the Cloud more than the Edge for deploying the software components of IoT systems, in the majority of the IoT application domains; and (ii) the main factors driving deployment decisions are four: reliability, performance, security, and cost.",,978-1-7281-7415-0,10.1109/ICSA-C50368.2020.00012,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095740,Industrial Survey;Deployment of IoT Systems;Deployment Decisions Drivers;Edge-Cloud Continuum,Hardware;Software;Computer architecture;Cloud computing;Unified modeling language;Sociology;Statistics,cloud computing;Internet of Things;object-oriented programming;software architecture,IoT systems;industrial survey;Internet of Things systems;design decisions concern;hardware infrastructure;edge-cloud continuum;optimal deployment models;extra-functional requirements;hardware resources;deployment decisions;IoT application;software component modeling;operational cost limits;legal issues,,6,,27,,19 May 2020,,,IEEE,IEEE Conferences,,
When IoT Data Meets Streaming in the Fog,"Low latency support, high data throughput, heterogeneity, geo-distribution, placement issues","12, 8, 3, 5, 11,",L. Ait-Oucheggou; M. I. Naas; Y. Hadjadj-Aoul; J. Boukhobza,,2022 IEEE 6th International Conference on Fog and Edge Computing (ICFEC),20 Jun 2022,2022,,,50,57,"IoT and video streaming are the main driving applications for digital data generation today. The traditional way of storing and processing data in the Cloud cannot satisfy many latency critical applications. This is why Fog computing emerged as a continuum infrastructure from the Cloud to end-user devices. Misplacing data in such an infrastructure results in high latency, and consequently increases the penalty for Internet Service Providers (ISPs) incurred by violating the service level agreement (SLA). In past studies, two issues have been investigated separately: the IoT data placement and the streaming cache placement. However, both placements rely on the same Fog distributed storage system. In this paper, we address those issues in a unique model with the aim to minimize the penalty for ISPs incurred by the SLA violation and maximize storage resources usage. We subdivided each Fog node storage space into a storage part and a cache part. First, our model consists in placing IoT data in the storage part of Fog nodes, and then placing streaming data in the cache part of these nodes. The novelty of our model is the flexibility it offers for managing the cache volume, which can, adaptively, spill on the free part dedicated to IoT data. Experiments show that using our model makes it possible to reduce the streaming data penalty of the ISP’s SLA violation by more than 47% on average.",,978-1-6654-9524-0,10.1109/ICFEC54809.2022.00014,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9798997,Data Placement;Fog;IoT;Streaming,Adaptation models;Cloud computing;Solid modeling;Costs;Web and internet services;Memory;Streaming media,cache storage;cloud computing;Internet;Internet of Things;optimisation;storage management;video streaming,Fog distributed storage system;unique model;ISPs;storage resources usage;Fog node storage space;storage part;cache part;placing IoT data;Fog nodes;cache volume;free part;streaming data penalty;ISP's SLA violation;IoT data meets streaming;main driving applications;digital data generation today;latency critical applications;Fog computing;continuum infrastructure;end-user devices;infrastructure results;high latency;Internet Service Providers;service level agreement;IoT data placement;streaming cache placement;placements,,,,24,IEEE,20 Jun 2022,,,IEEE,IEEE Conferences,,
POMT: Paired Offloading of Multiple Tasks in Heterogeneous Fog Networks,"Delay sensitivity, flexibility in providing resources, heterogeneity, dynamicity","12, 8, 5, 18,",Y. Yang; Z. Liu; X. Yang; K. Wang; X. Hong; X. Ge,,IEEE Internet of Things Journal,9 Oct 2019,2019,6,5,8658,8669,"By providing shared and flexible communication, computation, and storage resources along the cloud-to-things continuum, fog computing has become an attractive technology to support delay-sensitive applications in Internet of Things (IoT) and future wireless networks. Consider a typical heterogeneous fog network consisting of different types of fog nodes (FNs), wherein some task nodes (TNs) have computation-intensive and delay-sensitive tasks, while some helper nodes (HNs) have spare computation resources for sharing with their neighboring nodes. In order to minimize the delay of every task, these TNs and HNs should be effectively associated in a distributed manner, which is the fundamental multi-task multi-helper (MTMH) problem. To tackle this challenging problem, a potential game called paired offloading of multiple tasks (POMT) is formulated and studied. Theoretical analysis proves the existence of the Nash equilibrium (NE) for this proposed game. Further, the corresponding POMT algorithm is developed for every TN to achieve the NE of the general game. The analytical and simulation results show that our POMT algorithm can offer the near-optimal performance in system average delay and delay reduction ratio (DRR), and achieve more number of beneficial TNs, at two orders of magnitude lower complexity than a centralized optimal algorithm for computation offloading.",2327-4662,,10.1109/JIOT.2019.2922324,"National Natural Science Foundation of China(grant numbers:61801463,61571378); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735850,Computation offloading;delay-reduction ratio (DRR);fog computing;multi-task multi-helper (MTMH);potential game,Task analysis;Delays;Games;Internet of Things;Resource management;Cloud computing;Edge computing,cloud computing;game theory;Internet of Things;optimisation;synchronisation,heterogeneous fog networks;flexible communication;storage resources;cloud-to-things continuum;fog computing;delay-sensitive applications;future wireless networks;fog nodes;task nodes;delay-sensitive tasks;helper nodes;spare computation resources;neighboring nodes;delay reduction ratio;computation offloading;POMT algorithm;paired offloading of multiple tasks;multitask multihelper problem;Internet of Things;IoT;MTMH problem;Nash equilibrium;DRR;centralized optimal algorithm,,24,,35,IEEE,12 Jun 2019,,,IEEE,IEEE Journals,,
Mobility-Aware IoT Applications Placement in the Cloud Edge Continuum,"Heterogeneity, resource limitations, end-device mobility, conflicting objectives within the environment, placement challenges","8, 17, 13, 5, 1,",D. Kimovski; N. Mehran; C. E. Kerth; R. Prodan,,IEEE Transactions on Services Computing,,2021,PP,99,1,1,"The Edge computing extension of the Cloud services towards the network boundaries raises important placement challenges for IoT applications running in a heterogeneous environment with limited computing capacities. Unfortunately, existing works only partially address this challenge by optimizing a single or aggregate objective (e.g., response time) and not considering the edge devices' mobility and resource constraints. To address this gap, we propose a novel mobility-aware multi-objective IoT application placement (mMAPO) method in the Cloud -- Edge Continuum that optimizes completion time, energy consumption, and economic cost as conflicting objectives. mMAPO utilizes a Markov model for predictive analysis of the Edge device mobility and constrains the optimization to devices that do not frequently move through the network. We evaluate the quality of the mMAPO placements using simulation and real-world experimentation on two IoT applications. Compared to related work, mMAPO reduces the economic cost by 28% and decreases the completion time by 80% while maintaining a stable energy consumption.",1939-1374,,10.1109/TSC.2021.3094322,DataCloud H2020 Project;,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9473013,Cloud -Edge Continuum;mobility;application placement;multi-objective optimization;energy consumption;cost,Internet of Things;Cloud computing;Energy consumption;Optimization;Predictive models;Markov processes;Economics,,,,,,,CCBY,2 Jul 2021,,,IEEE,IEEE Early Access Articles,,
Latency estimation for fog-based internet of things,"Support for low latency and real time, ubiquitous computing, heterogeneity, mobility","12, 4, 8, 13,",J. Li; T. Zhang; J. Jin; Y. Yang; D. Yuan; L. Gao,,2017 27th International Telecommunication Networks and Applications Conference (ITNAC),18 Dec 2017,2017,,,1,6,"Low latency is critical for delay-sensitive applications such as video surveillance, live streaming, and online data analytics. Fog computing enables the emergence of the latency-sensitive internet of things (IoT) network to support real-time applications. While the distance between sensing and processing is minimized in the fog network, the cross-fog latency is yet to be determined. In this paper, we study the components of network delays and develop a latency estimation framework for fog-based IoT. The proposed framework, in particular, precisely predicts the end-to-end inter-node delay along the cloud-fog-things continuum. We investigate the benefits and use cases based on latency estimated by the proposed framework. A case study is further conducted to illustrate the validation and advantages, followed by future research directions.",2474-154X,978-1-5090-6796-1,10.1109/ATNAC.2017.8215403,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8215403,Fog computing;IoT;Vivaldi algorithm;GNP;latency,Delays;Peer-to-peer computing;Estimation;Springs;Economic indicators;Cloud computing;Servers,cloud computing;Internet of Things,IoT;cloud-fog-things continuum;delay-sensitive applications;fog computing;real-time applications;fog network;network delays;latency estimation framework;end-to-end internode delay;latency-sensitive Internet of Things network;fog-based Internet of Things;cross-fog latency,,19,,16,,18 Dec 2017,,,IEEE,IEEE Conferences,,
Querying Distributed Sensor Streams in the Edge-to-Cloud Continuum,"Hierarchical structure, geo-distibution, low latency","9, 3, 12, ",R. Karlstetter; R. Widhopf-Fenk; M. Schulz,,2022 IEEE International Conference on Edge Computing and Communications (EDGE),24 Aug 2022,2022,,,192,197,"Sensor data is of crucial importance in many IoT scenarios. It is used for online monitoring as well as long term data analytics, enabling countless use cases from damage prevention to predictive maintenance. Multivariate sensor time series data is acquired and initially stored close to the sensor, at the edge. It is also beneficial to summarize this data in windowed aggregations at different resolutions. A subset of the resulting aggregation hierarchy is typically sent to a cloud infrastructure, often via intermittent or low bandwidth connections. Consequently, different views on the data exist on different nodes in the edge-to-cloud continuum. However, when querying this data, users are interested in a fast response and a complete, unified view on the data, regardless of which part in the infrastructure continuum they send the query to and where the data is physically stored. In this paper, we present a loosely coupled approach that enables fast range queries on a distributed and hierarchical sensor database. Our system only assumes the possibility of fast local range queries on a hierarchical sensor database. It does not require any shared state between nodes and thus degrades gracefully in case certain parts of the hierarchy are unreachable. We show that our system is suitable for driving interactive data exploration sessions on terabytes of data while unifying the different views on the data. Thus, our system can improve the data analysis experience in many geo-distributed scenarios.",2767-9918,978-1-6654-8140-3,10.1109/EDGE55608.2022.00035,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9860303,edge;cloud;multivariate sensor data stream;distributed query,Cloud computing;Data analysis;Time series analysis;Distributed databases;Memory;Bandwidth;Data communication,data analysis;distributed sensors;Internet of Things;query processing;time series;wireless sensor networks,distributed sensor streams;edge-to-cloud continuum;sensor data;IoT scenarios;online monitoring;long term data analytics;countless use cases;damage prevention;multivariate sensor time series data;windowed aggregations;resulting aggregation hierarchy;cloud infrastructure;low bandwidth connections;complete view;infrastructure continuum;fast range queries;distributed sensor database;hierarchical sensor database;fast local range queries;case certain parts;interactive data exploration sessions;data analysis experience;geo-distributed scenarios,,,,15,IEEE,24 Aug 2022,,,IEEE,IEEE Conferences,,
Performance Evaluation of an Internet of Healthcare Things for Medical Monitoring Using M/M/c/K Queuing Models,"Layered structure, resource utilization awareness, latency awareness, device interoperability","9, 17, 12, 10,",F. A. Silva; T. A. Nguyen; I. Fé; C. Brito; D. Min; J. -W. Lee,,IEEE Access,13 Apr 2021,2021,9,,55271,55283,"Due to the non-stop and rapid spreading of virus pandemics all over the world, traditional healthcare monitoring capabilities of hospitals and/or medical centers are under a severe over-load. Modern computing infrastructures with the harmony of various layers of computing paradigms (e.g., cloud/fog/edge computing) for healthcare monitoring are apparently the essential computing backbone that help access and process instantly the medical data of every single patient at the very edge of the healthcare system to combat with global or regional virus contagion. Previous studies proposed different computing system architectures for healthcare monitoring but few works considered the evaluation of pure performance of medical data transmission in a comprehensive manner. In this paper, we proposed an M/M/c/K queuing network model for the performance evaluation of an Internet of Healthcare Things (IoHT) infrastructure in association with a three layer cloud/fog/edge computing continuum. The model considers a life cycle of medical data from body-attached IoT sensors in edge layer all the way to local clients (e.g., local medical doctors, physicians) through fog layer and to remote clients (e.g., medical professionals, patient's family members) through cloud layer. Furthermore, we also explore the impact of the alteration in system configuration and computing capability of computing layers in two scenarios on various performance metrics. Critical performance metrics related to quality of service are evaluated in a comprehensive manner, such as (i) mean response time of medical data transmission to fog (local) clients and to cloud (remote) clients, (ii) utilization of cloud/fog/edge computing layers, (iii) service throughput, (iv) number of medical messages in a period of time, and (v) drop rate. The simulation results pinpoint bottle-neck parameters and configurations of the IoHT infrastructure's system architecture in relation to the frequency of medical data collection for health check of patients. Thus, the findings of this study can help improve medical administration in hospitals and healthcare centers and help design computing infrastructures in accordance for medical monitoring in the severe circumstances of virus pandemics.",2169-3536,,10.1109/ACCESS.2021.3071508,"Brazilian National Council for Scientific and Technological Development—CNPq(grant numbers:309335/2017-5); Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education(grant numbers:2020R1A6A1A03046811); Ministry of Science, ICT (MSIT), South Korea, through the Information Technology Research Center (ITRC) Support Program supervised by the Institute for Information & communications Technology Planning & Evaluation (IITP)(grant numbers:IITP-2020-2016-0-00465); “The Competency Development Program for Industry Specialist“ of the Korean Ministry of Trade, Industry, and Energy (MOTIE), operated by the Korea Institute for Advancement of Technology (KIAT)(grant numbers:N0002428); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9398691,Healthcare monitoring;internet of healthcare things;queuing model;performance evaluation;quality of service,Cloud computing;Monitoring;Performance evaluation;Measurement;Hospitals;Internet of Things;Computational modeling,cloud computing;data handling;diseases;epidemics;health care;Internet of Things;medical information systems;patient monitoring;quality of service;queueing theory;telemedicine,performance evaluation;medical monitoring;virus pandemics;healthcare monitoring;hospitals;medical centers;modern computing infrastructures;help access;healthcare system;medical data transmission;comprehensive manner;Healthcare Things infrastructure;body-attached IoT sensors;edge layer;local medical doctors;fog layer;remote clients;medical professionals;cloud layer;system configuration;computing capability;critical performance metrics;fog clients;medical messages;IoHT infrastructure;medical data collection;medical administration;healthcare centers;computing backbone;Internet of Healthcare Things;M/M/c/K queuing models;computing system architectures;virus contagion;cloud computing;fog computing;edge computing;patient medical data;patient family members;service throughput;bottle-neck parameters;patient health check;quality of service,,4,,35,CCBY,7 Apr 2021,,,IEEE,IEEE Journals,,
ICCF: An Information-Centric Collaborative Fog Platform for Building Energy Management Systems,"Heterogeneity, hierarchy, geo-distribution","9, 8, 3, ",Z. Shen; T. Zhang; J. Jin; K. Yokota; A. Tagami; T. Higashino,,IEEE Access,3 Apr 2019,2019,7,,40402,40415,"In order to construct future large-scale Internet of Things (IoT) networks, Fog computing is a promising paradigm that brings big data processing capability, storage, and control from a remote cloud closer to the end users/things. However, the majority of prior studies have focused on the data connection to realize a vertical Cloud-Fog-devices' continuum. In this paper, we propose an information-centric collaborative Fog (ICCF) platform, empowered by a novel horizontal Fog-to-Fog layer. Specifically, the ICCF enhances sensor data processing performance by enabling horizontal data transfer in the Fog layer through connectionless name-based Fog-to-Fog data transmission. It utilizes the Fog node's distributed data processing power to achieve a satisfactory data processing performance, while communication with the Cloud is only required to report detected anomalies. Moreover, because the connectionless name-based scheme significantly reduces data connection overhead, this guarantees real-time communication and the ability of processing large-scale IoT data. Building energy management system (BEMS) for detecting abnormal sensor data is adopted as a case study to illustrate our design philosophy and, more importantly, to validate the advantages of the proposed ICCF by conducting a variety of experiments based on the sensor data collected from a real-world indoor environment.",2169-3536,,10.1109/ACCESS.2019.2906645,"“Research and Development of Innovative Network Technologies to Create the Future(grant numbers:19103); Commissioned Research of National Institute of Information and Communications Technology (NICT), Japan; Australian Government Research Training Program Scholarship; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8672574,Building energy management system;fog computing;information-centric networking;Internet of Things;machine learning;sensor data processing,Edge computing;Cloud computing;Buildings;Data processing;Energy management;Collaboration;Data communication,Big Data;building management systems;cloud computing;energy management systems;Internet of Things;wireless sensor networks,remote cloud;ICCF;sensor data processing performance;horizontal data transfer;connectionless name-based scheme;large-scale IoT data;abnormal sensor data;building energy management systems;data connection;information-centric collaborative fog platform;Internet of Things networks;fog computing;big data processing;vertical cloud-fog-devices continuum;horizontal fog-to-fog layer;connectionless name-based fog-to-fog data transmission;fog node distributed data processing power;anomalies detection,,9,,34,OAPA,21 Mar 2019,,,IEEE,IEEE Journals,,
Automating Edge-to-cloud Workflows for Science: Traversing the Edge-to-cloud Continuum with Pegasus,"Heterogeneity, geographical diversity, reduced response times, handling data privacy constraints, masking network outages","8, 3, 12, 15, 24,",R. Tanaka; G. Papadimitriou; S. C. Viswanath; C. Wang; E. Lyons; K. Thareja; C. Qu; A. Esquivel; E. Deelman; A. Mandal; P. Calyam; M. Zink,,"2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",19 Jul 2022,2022,,,826,833,"In this paper, we describe how we extended the Pegasus Workflow Management System to support edge-to-cloud workflows in an automated fashion. We discuss how Pegasus and HTCondor (its job scheduler) work together to enable this automation. We use HTCondor to form heterogeneous pools of compute resources and Pegasus to plan the workflow onto these resources and manage containers and data movement for executing workflows in hybrid edge-cloud environments. We then show how Pegasus can be used to evaluate the execution of workflows running on edge only, cloud only, and edge-cloud hybrid environments. Using the Chameleon Cloud testbed to set up and configure an edge-cloud environment, we use Pegasus to benchmark the executions of one synthetic workflow and two production workflows: CASA-Wind and the Ocean Observatories Initiative Orcasound workflow, all of which derive their data from edge devices. We present the performance impact on workflow runs of job and data placement strategies employed by Pegasus when configured to run in the above three execution environments. Results show that the synthetic workflow performs best in an edge only environment, while the CASA - Wind and Orcasound workflows see significant improvements in overall makespan when run in a cloud only environment. The results demonstrate that Pegasus can be used to automate edge-to-cloud science workflows and the workflow provenance data collection capabilities of the Pegasus monitoring daemon enable computer scientists to conduct edge-to-cloud research.",,978-1-6654-9956-9,10.1109/CCGrid54584.2022.00098,"NSF(grant numbers:2018074,1664162); University of Wisconsin-Madison; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825937,Pegasus;edge computing;workflows;workflow management systems;clouds;distributed systems,Performance evaluation;Cloud computing;Observatories;Oceans;Production;Data collection;Containers,cloud computing;data analysis;natural sciences computing;scheduling;workflow management software,edge-to-cloud workflows;edge-to-cloud continuum;Pegasus workflow management system;edge-cloud hybrid environments;Chameleon cloud;production workflows;execution environments;synthetic workflow performs;edge-to-cloud science workflows;workflow provenance data collection capabilities;Pegasus monitoring daemon;edge-to-cloud research;ocean observatories initiative orcasound workflow,,,,31,IEEE,19 Jul 2022,,,IEEE,IEEE Conferences,,
Offloading Execution from Edge to Cloud: A Dynamic Node-RED Based Approach,"Offloading, resource awareness, deployment management issues","14, 17, 5, ",R. Sosa; C. Kiraly; J. D. Parra Rodriguez,,2018 IEEE International Conference on Cloud Computing Technology and Science (CloudCom),27 Dec 2018,2018,,,149,152,"Fog computing enables use cases where data produced in end devices are stored, processed, and acted on directly at the edges of the network, yet computation can be offloaded to more powerful instances through the edge to cloud continuum. Such offloading mechanism is especially needed in case of modern multi-purpose IoT gateways, where both demand and operation conditions can vary largely between deployments. To facilitate the development and operations of gateways, we implement offloading directly as part of the IoT rapid prototyping process embedded in the software stack, based on Node-RED. We evaluate the implemented method using an image processing example, and compare various offloading strategies based on resource consumption and other system metrics, highlighting the differences in handling demand and service levels reached.",2330-2186,978-1-5386-7899-2,10.1109/CloudCom2018.2018.00039,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8591008,"Fog computing, dynamic offloading, Internet of Things, IoT gateways",Logic gates;Cloud computing;Software;Task analysis;Rapid prototyping;Measurement;Internet of Things,cloud computing;Internet of Things;internetworking;mobile computing,image processing;offloading strategies;implemented method;software stack;IoT rapid prototyping process;operation conditions;modern multipurpose IoT gateways;offloading mechanism;cloud continuum;end devices;fog computing;dynamic Node-RED,,3,,10,,27 Dec 2018,,,IEEE,IEEE Conferences,,
Learning and Management for Internet of Things: Accounting for Adaptivity and Scalability,"Intelligent infrastructure, extreme heterogeneity, unpredictability, human interaction, latency constraints","6, 8, 18, 25, 12,",T. Chen; S. Barbarossa; X. Wang; G. B. Giannakis; Z. -L. Zhang,,Proceedings of the IEEE,26 Mar 2019,2019,107,4,778,796,"Internet of Things (IoT) envisions an intelligent infrastructure of networked smart devices offering task-specific monitoring and control services. The unique features of IoT include extreme heterogeneity, massive number of devices, and unpredictable dynamics partially due to human interaction. These call for foundational innovations in network design and management. Ideally, it should allow efficient adaptation to changing environments, and low-cost implementation scalable to a massive number of devices, subject to stringent latency constraints. To this end, the overarching goal of this paper is to outline a unified framework for online learning and management policies in IoT through joint advances in communication, networking, learning, and optimization. From the network architecture vantage point, the unified framework leverages a promising fog architecture that enables smart devices to have proximity access to cloud functionalities at the network edge, along the cloud-to-things continuum. From the algorithmic perspective, key innovations target online approaches adaptive to different degrees of nonstationarity in IoT dynamics, and their scalable model-free implementation under limited feedback that motivates blind or bandit approaches. The proposed framework aspires to offer a stepping stone that leads to systematic designs and analysis of task-specific learning and management schemes for IoT, along with a host of new research directions to build on.",1558-2256,,10.1109/JPROC.2019.2896243,"National Science Foundation(grant numbers:1509040,1508993,1711471); H2020 Europe-Japan Project 5G-MiEdge(grant numbers:723171); National Natural Science Foundation of China(grant numbers:61671154); National Key Research and Development Program of China(grant numbers:2017YFB0403402); Science and Technology Commission of Shanghai Municipality(grant numbers:17510710400); U.S. Department of Defense(grant numbers:HDTRA1-14-1-0040); National Science Foundation(grant numbers:1411636,1617729); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648462,Internet of Things (IoT);mobile edge computing (MEC);network resource allocation;online learning;stochastic optimization,Internet of Things;Scalability;Vehicle dynamics;Task analysis;Communication networks;Resource management;Stochastic processes;Online services,computer network management;Internet of Things;learning (artificial intelligence),intelligent infrastructure;networked smart devices;task-specific monitoring;extreme heterogeneity;unpredictable dynamics;human interaction;foundational innovations;network design;stringent latency constraints;overarching goal;online learning;network architecture vantage point;promising fog architecture;network edge;cloud-to-things continuum;key innovations;online approaches;IoT dynamics;scalable model-free implementation;task-specific learning;Internet of Things,,47,,111,IEEE,21 Feb 2019,,,IEEE,IEEE Journals,,
A Review of Application Layer Communication Protocols for the IoT Edge Cloud Continuum,"Layered structure, edge intelligence, cross-level communication and application deployment","9, 6, 2, ",J. Kampars; D. Tropins; R. Matisons,,2021 62nd International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS),23 Nov 2021,2021,,,1,6,"The IoT technological paradigm has become widespread and has found its place within industries such as smart cities, smart grids, smart homes, physical security, e-health, asset management, and logistics. Around 50 billion various devices will soon be connected to the Internet. A hot topic within the IoT field is edge computing, which adds extra computing capacity to the edge allowing to perform computationally intensive operations like execution of Deep Neural Networks possibly requiring specialized devices equipped with Graphical Processing Units. Optimal construction of solutions that span the IoT, edge, and cloud computing layers is still an open research area, and it is believed that edge computing is in its infancy. This article reviews application layer protocols that can be used to interconnect entities belonging to the three previously mentioned layers.",,978-1-6654-0615-4,10.1109/ITMS52826.2021.9615332,European Regional Development Fund;,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615332,AMQP;CoAP;DDS;edge computing;gRPC;IoT;MQTT;XMPP,Performance evaluation;Cloud computing;Protocols;Smart cities;Smart homes;Smart grids;Security,cloud computing;Internet of Things;protocols,edge computing;computationally intensive operations;deep neural networks;graphical processing units;cloud computing;application layer communication protocols;IoT edge cloud continuum;Internet,,,,35,IEEE,23 Nov 2021,,,IEEE,IEEE Conferences,,
Cloud — Edge Offloading Model for Vehicular Traffic Analysis,"Resource management challenges, task offloading, response time awareness, energy efficiency, edge intelligence","17, 14, 12, 7, 6,",D. Kimovski; D. C. Bogatinoska; N. Mehran; A. Karadimce; N. Paunkoska; R. Prodan; N. Marina,,"2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)",4 Jun 2021,2020,,,746,753,"The proliferation of smart sensing and computing devices, capable of collecting a vast amount of data, has made the gathering of the necessary vehicular traffic data relatively easy. However, the analysis of these big data sets requires computational resources, which are currently provided by the Cloud Data Centers. Nevertheless, the Cloud Data Centers can have unacceptably high latency for vehicular analysis applications with strict time requirements. The recent introduction of the Edge computing paradigm, as an extension of the Cloud services, has partially moved the processing of big data closer to the data sources, thus addressing this issue. Unfortunately, this unlocked multiple challenges related to resources management. Therefore, we present a model for scheduling of vehicular traffic analysis applications with partial task offloading across the Cloud - Edge continuum. The approach represents the traffic applications as a set of interconnected tasks composed into a workflow that can be partially offloaded to the Edge. We evaluated the approach through a simulated Cloud - Edge environment that considers two representative vehicular traffic applications with a focus on video stream analysis. Our results show that the presented approach reduces the application response time up to eight times while improving energy efficiency by a factor of four.",,978-1-6654-1485-2,10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443969,Edge offloading;Cloud - Edge continuum;Application Scheduling;Particle Swarm Optimization,Analytical models;Data centers;Processor scheduling;Image edge detection;Computational modeling;Streaming media;Energy efficiency,Big Data;cloud computing;computer centres;scheduling;video streaming,Cloud - Edge offloading model;smart sensing;computing devices;necessary vehicular traffic data;big data sets;computational resources;Cloud Data Centers;vehicular analysis applications;strict time requirements;Edge computing paradigm;Cloud services;data sources;vehicular traffic analysis applications;partial task offloading;Cloud - Edge continuum;simulated Cloud - Edge environment;representative vehicular traffic applications;video stream analysis;application response time,,,,21,,4 Jun 2021,,,IEEE,IEEE Conferences,,
MQTT-based Middleware for Container Support in Fog Computing Environments,"Offloading, migration support, dynamicity","14, 13, 5, ",P. Bellavista; L. Foschini; N. Ghiselli; A. Reale,,2019 IEEE Symposium on Computers and Communications (ISCC),27 Jan 2020,2019,,,1,7,"Distributed architectures where the Internet of Things (IoT) and the cloud are efficiently integrated play an increasingly important role for IoT solutions. Among these architectures, there is a growing interest in the ones that support the opportunity of functionality offloading towards either intermediate fog nodes or IoT end devices. Relevant existing research work has mainly focused so far on virtual machine and container migration to intermediate fog nodes and on migration of very simple functions to IoT endpoints (to preserve their limited resources available). In this paper, we originally concentrate on the gap associated with benefitting from fog functionality at resource-powerful IoT endpoints, to create a continuum deployment that glues IoT devices and the cloud. In particular, this paper originally presents a middleware that manages application deployment and life-cycle by simplifying and optimizing management operations such as device configuration and application constraint satisfaction. The proposed solution particularly fits highly articulated scenarios with large numbers of IoT devices and intermediate fog nodes, by supporting the opportunity to offload functionality in a split way between IoT endpoints and edge nodes. The reported experimental results confirm the feasibility of our approach in term of overhead, scalability, and application life-cycle management.",2642-7389,978-1-7281-2999-0,10.1109/ISCC47284.2019.8969615,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969615,IoT;Fog Computing;Multi-access Edge Computing;Middleware;IBM Watson IoT™;MQTT,Internet of Things;Computer architecture;Middleware;Cloud computing;Performance evaluation;Containers;Standards,Internet of Things;middleware;virtual machines,MQTT-based middleware;container support;fog computing environments;distributed architectures;IoT solutions;functionality offloading;intermediate fog nodes;IoT end devices;research work;virtual machine;container migration;simple functions;fog functionality;resource-powerful IoT endpoints;IoT devices;device configuration;application constraint satisfaction;application life-cycle management,,3,,15,,27 Jan 2020,,,IEEE,IEEE Conferences,,
Analytics Everywhere for Streaming IoT Data,"Data heterogeneuity, geographical distribution, high throughput","8, 3, 11,",H. Cao; M. Wachowicz,,"2019 Sixth International Conference on Internet of Things: Systems, Management and Security (IOTSMS)",23 Dec 2019,2019,,,18,25,"Exploring new insights from IoT data means not only providing higher-level intelligence in a timely way but also generating long-term predictions and decisions from historical IoT data. This paper aims to explore the synergy of various data rates, message passing, and processing algorithms to support streaming analytics at the edge, fog, and cloud computing environments. Towards this end, we present an IoT architecture that is capable of capturing, managing, processing, analyzing, and visualizing IoT data streams. For validation purposes, a smart parking scenario is used to evaluate our architecture.",,978-1-7281-2949-5,10.1109/IOTSMS48152.2019.8939171,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939171,IoT data streams;streaming analytics;smart parking;IoT architecture;integrated fabric;edge/fog/cloud continuum,,cloud computing;data analysis;data visualisation;Internet of Things;message passing,higher-level intelligence;IoT data streaming;data rates;streaming analytics;IoT architecture;message passing;edge computing environments;fog computing environments;cloud computing environments;IoT data streams visualization;smart parking scenario,,2,,24,,23 Dec 2019,,,IEEE,IEEE Conferences,,
"E2Clab: Exploring the Computing Continuum through Repeatable, Replicable and Reproducible Edge-to-Cloud Experiments","Complex physical infrastructure, multi-tier architecture, AI usage","4, 9, 6,",D. Rosendo; P. Silva; M. Simonin; A. Costan; G. Antoniu,,2020 IEEE International Conference on Cluster Computing (CLUSTER),2 Nov 2020,2020,,,176,186,"Distributed digital infrastructures for computation and analytics are now evolving towards an interconnected ecosystem allowing complex applications to be executed from IoT Edge devices to the HPC Cloud (aka the Computing Continuum, the Digital Continuum, or the Transcontinuum). Understanding end-to-end performance in such a complex continuum is challenging. This breaks down to reconciling many, typically contradicting application requirements and constraints with low-level infrastructure design choices. One important challenge is to accurately reproduce relevant behaviors of a given application workflow and representative settings of the physical infrastructure underlying this complex continuum. In this paper we introduce a rigorous methodology for such a process and validate it through E2Clab. It is the first platform to support the complete analysis cycle of an application on the Computing Continuum: (i) the configuration of the experimental environment, libraries and frameworks; (ii) the mapping between the application parts and machines on the Edge, Fog and Cloud; (iii) the deployment of the application on the infrastructure; (iv) the automated execution; and (v) the gathering of experiment metrics. We illustrate its usage with a real-life application deployed on the Grid'5000 testbed, showing that our framework allows one to understand and improve performance, by correlating it to the parameter settings, the resource usage and the specifics of the underlying infrastructure.",2168-9253,978-1-7281-6677-3,10.1109/CLUSTER49012.2020.00028,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229592,Reproducibility;Methodology;Computing Continuum;Edge Intelligence,Performance evaluation;Conferences;Ecosystems;Cluster computing;Libraries,cloud computing;Internet of Things;parallel processing,resource usage;parameter settings;automated execution;transcontinuum;digital continuum;real-life application;physical infrastructure;application workflow;low-level infrastructure design choices;application requirements;complex continuum;end-to-end performance;Digital Continuum;HPC Cloud;IoT Edge devices;distributed digital infrastructures;edge-to-cloud experiments;computing continuum;E2Clab,,7,,48,,2 Nov 2020,,,IEEE,IEEE Conferences,,
Poster Abstract: C-Continuum: Edge-to-Cloud computing for distributed AI,"Distributed AI, heterogeneity, uncertainty and dynamicity","6, 8, 18, 5,",D. Aguiari; A. Ferlini; J. Cao; S. Guo; G. Pau,,IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),23 Sep 2019,2019,,,1053,1054,"Mobile autonomous systems are supposed to deeply impact in manufacturing, space exploration, rescue, defense, transportation, and everyday life. Autonomous air-ground vehicles, for example, will become normal tools in the next few years, providing a natural platform for distributed artificial intelligence applications including, for example, disaster rescue and recovery, area surveying, autonomous driving, etc. The raise of autonomous cooperating robots will pose new challenges in networking, distributed systems and resource management. Heavy computational tasks will be dispatched to the closest edge node for processing and the core-cloud will be involved as last resort in an effort to reduce latency and increase the global system capacity leveraging application and resource locality. Massive amounts of data and computations will be required. For example, in the autonomous driving scenario Intel estimates that each driver-less vehicle will produce over 4 TeraBytes of data each day1. While most of this data is consumed in-car, cooperating autonomous vehicles will have to exchange some percentage of the 4TB and eventually offload some computation and data to the local edge or the core-cloud. This is particularly relevant when locally gathered and labeled data can be used to refine the model and ultimately increase the global “intelligence”. This approach is often taken by autonomous driving automakers.",,978-1-7281-1878-9,10.1109/INFCOMW.2019.8845170,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845170,cloud computing;edge computing;name data networking;v2i;v2v,Task analysis;Autonomous vehicles;Resource management;Computational modeling;Edge computing;Atmospheric modeling,artificial intelligence;automobile manufacture;cloud computing;cooperative systems;mobile robots;multi-robot systems,c-continuum;edge-to-cloud computing;distributed AI;mobile autonomous systems;autonomous air-ground vehicles;distributed artificial intelligence applications;autonomous cooperating robots;distributed systems;resource management;autonomous driving automakers,,2,,4,,23 Sep 2019,,,IEEE,IEEE Conferences,,
Edge-Cloud Intelligence in Self-Diagnostic of Land Mobile Radio Systems,"Data heterogeneuity, edge intelligence, self-diagnosis","8, 6, 16, ",H. Cao; M. Wachowicz; J. Craig,,2021 IEEE 7th World Forum on Internet of Things (WF-IoT),9 Nov 2021,2021,,,645,650,"IIoT sensors are usually deployed on a massive scale with stringent scalability, modularity, and interoperability requirements. It is indisputable that they produce a large amount of high-speed and heterogeneous data streams that pose many challenges to perform management, processing, and analytical tasks. This paper proposes an integrated edge-cloud continuum platform that can harvest IIoT data streams from a variety of sensors deployed at a remote RF site; and can harmonize different machine learning models for diagnosing problems that enhance infrastructure monitoring and long-term structural resilience. A real-world experiment was carried out to evaluate the proposed platform for supporting a self-diagnostic process for intelligent maintenance of Land Mobile Radio (LMR) infrastructures.",,978-1-6654-4431-6,10.1109/WF-IoT51360.2021.9595618,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9595618,cloud computing;edge computing;Land Mobile Radio Systems;Industrial Internet of Things;streaming analytics;intelligent maintenance,Radio frequency;Scalability;Machine learning;Maintenance engineering;Task analysis;Monitoring;Interoperability,cloud computing;data handling;Internet of Things;land mobile radio;learning (artificial intelligence),IIoT sensors;interoperability requirements;heterogeneous data streams;analytical tasks;integrated edge-cloud continuum platform;remote RF site;infrastructure monitoring;long-term structural resilience;self-diagnostic process;intelligent maintenance;edge-cloud intelligence;land mobile radio systems;IIoT data stream harvesting;machine learning models;LMR infrastructure,,,,22,IEEE,9 Nov 2021,,,IEEE,IEEE Conferences,,
Joint Optimization of Energy Consumption and Delay in Cloud-to-Thing Continuum,"Delay requirements, energy consumption requirements","12, 7, 17, ",X. Wei; C. Tang; J. Fan; S. Subramaniam,,IEEE Internet of Things Journal,8 May 2019,2019,6,2,2325,2337,"Unmanned aerial vehicles (UAVs) are considered a promising solution for carrying communications and computational facilities to increase the flexibility of cloud-to-thing continuum, where short-range and long-range wireless links are adopted to connect mobile devices to the fog node and the fog node to the remote data center, respectively. Most existing UAV-involved resource allocation algorithms focus mainly on the radio resource allocation problem, and much less attention has been paid to the allocation of computational resources. Moreover, the dynamic arrival of tasks and the queueing delay at each computation entity is usually neglected. In this paper, a joint optimization problem is formulated that takes the weighted sum of energy consumption and delay experienced by tasks as the objective function. Processing frequencies and transmission powers of mobile devices and the fog node are the decision variables in the problem. To solve this problem, three decision-making algorithms are presented. The first one is used to decide the UAV's position. The processing frequency, transmission power, and task assignment results at mobile devices are determined by the second algorithm. The last one is adopted by the fog node to optimize its processing frequency and transmission power. A series of simulation experiments are conducted to evaluate the effectiveness of the proposed algorithms. Compared with the random task assignment scheme with fixed parameters, the combination of our three algorithms always perform much better for a wide range of parameter settings.",2327-4662,,10.1109/JIOT.2019.2906287,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8671693,Cloud-to-thing;fog computing;optimization;scheduling,Task analysis;Delays;Mobile handsets;Cloud computing;Energy consumption;Wireless communication;Resource management,autonomous aerial vehicles;decision making;mobile handsets;optimisation;remotely operated vehicles;resource allocation,computational facilities;cloud-to-thing continuum;mobile devices;fog node;remote data center;radio resource allocation problem;computational resources;queueing delay;computation entity;joint optimization problem;energy consumption;transmission powers;decision-making algorithms;processing frequency;transmission power;random task assignment scheme;unmanned aerial vehicles;UAVs;short-range wireless links;parameter settings;long-range wireless links,,29,,29,IEEE,20 Mar 2019,,,IEEE,IEEE Journals,,
DATS: Dispersive Stable Task Scheduling in Heterogeneous Fog Networks,"Embedded AI, delay requirements, heterogeneity, data heterogeneity, energy consumption requirements","6, 12, 8, 17, 7,",Z. Liu; X. Yang; Y. Yang; K. Wang; G. Mao,,IEEE Internet of Things Journal,8 May 2019,2019,6,2,3423,3436,"Fog computing has risen as a promising architecture for future Internet of Things, 5G and embedded artificial intelligence applications with stringent service delay requirements along the cloud to things continuum. For a typical fog network consisting of heterogeneous fog nodes (FNs) with different computing resources and communication capabilities, how to effectively schedule complex computation tasks to multiple FNs in the neighborhood to achieve minimal service delay is a fundamental challenge. To tackle this problem, a new concept named processing efficiency (PE) is first defined to incorporate computing resources and communication capacities. Further, to minimize service delay in heterogeneous fog networks, a scalable, stable, and decentralized algorithm, namely dispersive stable task scheduling (DATS), is proposed and evaluated, which consists of two key components: 1) a PE-based progressive computing resources competition and 2) a QoE-oriented synchronized task scheduling. Theoretical proofs and simulation results show that the proposed DATS algorithm can achieve effective tradeoff between computing resources and communication capabilities, thus significantly reducing service delay in heterogeneous fog networks.",2327-4662,,10.1109/JIOT.2018.2884720,"Science and Technology Commission of Shanghai Municipality(grant numbers:17ZR1429200,18511106500); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8556474,Computation offloading;fog computing;matching theory;task scheduling,Task analysis;Cloud computing;Delays;Computational modeling;Processor scheduling;Edge computing;Scheduling,artificial intelligence;cloud computing;Internet;resource allocation;telecommunication scheduling,heterogeneous fog networks;dispersive stable task scheduling;DATS;communication capabilities;fog computing;artificial intelligence applications;stringent service delay requirements;heterogeneous fog nodes;complex computation tasks;minimal service delay;communication capacities;computing resources,,34,,37,IEEE,2 Dec 2018,,,IEEE,IEEE Journals,,
In the Fog: Application Deployment for the Cloud Continuum,"Heterogeneity, energy constraints, latency constraints","8, 17, 12, ",D. Apostolou; Y. Verginadis; G. Mentzas,,"2021 12th International Conference on Information, Intelligence, Systems & Applications (IISA)",8 Oct 2021,2021,,,1,7,"Serverless and the Function-as-a-Service (FaaS) paradigms are seen as two enabling technologies for next-generation computing on the cloud continuum. This article discusses prominent frameworks to deploy and monitor applications that span the cloud continuum. It discusses associated challenges and proposes a novel architecture for a framework that manages intelligently multi-cloud, fog and edge resources in order to cope with the requirements of FaaS-enabled applications and services.",,978-1-6654-0032-9,10.1109/IISA52424.2021.9555532,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555532,cloud continuum;fog computing;serverless,Cloud computing;Image edge detection;FAA;Telecommunication traffic;Tools;Throughput;Task analysis,cloud computing;resource allocation;service-oriented architecture,application deployment;cloud continuum;next-generation computing;fog;FaaS-enabled applications;function-as-a-service paradigms;application monitoring;multicloud resource management;fog resource management;edge resource management,,,,18,,8 Oct 2021,,,IEEE,IEEE Conferences,,
OTE: Optimal Trustworthy EdgeAI solutions for smart cities,"Edge AI, unpredictability, environmental requirements, autonomy, mobility, privacy","6, 18, 7, 1, 13, 15,",V. Mygdalis; L. Carnevale; J. R. Martínez-De-Dios; D. Shutin; G. Aiello; M. Villari; I. Pitas,,"2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",19 Jul 2022,2022,,,842,850,"This work studies and defines the problem of providing extensive and opportunistic Edge AI-based area coverage in smart city application scenarios, by researching and determining the optimal configuration of sensing and computational resources for minimizing the environmental/technology footprint of the solution. A typical smart city computing continuum consists of statically installed multimodal sensing Internet-of-Things (IoT) nodes at various city locations, accompanied by interconnected computational Cloud/Edge/IoT nodes. This paper presents Optimal Trustworthy EdgeAI (OTE), an entirely novel research pipeline, that complements existing smart city infrastructure with intelligent drone Edge/IoT nodes (in the form of modularly equipped unmanned aerial vehicles), capable of autonomous repositioning according to individual/collective sensing and coverage criteria. Thereby, we envisage the emerging cutting-edge technologies of trustworthy sensing, perceiving, modelling technologies for predicting the behavior of moving targets (e.g., citizens/vehicles/objects), understanding natural phenomena (e.g., sea wave motion, urban flora/fauna, biodiversity) in order to anticipate events (people's bad habits, environmental changes), by exploiting novel continuous data processing services across the whole span of the enhanced Cloud-Edge-IoT computing continuum.",,978-1-6654-9956-9,10.1109/CCGrid54584.2022.00100,"Horizon 2020(grant numbers:871479,101004605); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826103,EdgeAI;Trustworthy-AI;Smart city;Cloud-Edge-IoT intelligence;UAVs,Cloud computing;Privacy;Smart cities;Pipelines;Semantics;Robot sensing systems;Software,artificial intelligence;autonomous aerial vehicles;cloud computing;Internet of Things;mobile robots;sensor fusion;smart cities;telerobotics;trusted computing,autonomous repositioning;continuous data processing services;intelligent drone edge-IoT nodes;Cloud-Edge-IoT computing continuum;multimodal sensing Internet-of-Things;modularly equipped unmanned aerial vehicles;extensive Edge AI-based area coverage;smart cities;optimal trustworthy EdgeAI solutions;OTE,,,,45,IEEE,19 Jul 2022,,,IEEE,IEEE Conferences,,
"Ecosystem of Things: Hardware, Software, and Architecture","Hierarchical structure, adaptive architecture, smart workloads, software flexibility","9, 5, 6, 2,",L. Chao; X. Peng; Z. Xu; L. Zhang,,Proceedings of the IEEE,6 Aug 2019,2019,107,8,1563,1583,"Edge computing is a continuum that includes the computing resources from cloud to things. Ecosystem of things (EoT) is a subsystem of the ecosystem of edge computing, which potentially contains trillions of devices of things and directly interacts with the physical world. This paper surveys the state of the art of EoT by focusing on the computing infrastructure aspect with a forward-looking perspective. We point out a trend of smart edge computing with four types of smartness and intelligence. We address three fundamental questions. 1) What capabilities and how much energy efficiency are the hardware providing? What is the future growth potential? 2) What abstractions are provided by the system software? Are they adequate to support smart edge computing? 3) What ecosystem architectures have been proposed for the coordination of things, the edge, and the cloud? Are they meeting the needs to encourage innovation but avoid unnecessary ecosystem fragmentation? We examine advances from both industry and academia, including research results, visions, and project concepts. We also point out future research directions.",1558-2256,,10.1109/JPROC.2019.2925526,National Natural Science Foundation of China(grant numbers:61532016); CAS Pioneer Hundred Talents Program(grant numbers:Y704061000);,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8768345,Architecture;ecosystem of things (EoT);edge computing;hardware;Internet of Things (IoT);software,Edge computing;Ecosystems;Computer architecture;Cloud computing;Software engineering;Internet of Things;Smart phones,Internet of Things;software architecture,ecosystem architectures;computing resources;EoT;smart edge computing;computing infrastructure;Ecosystem of Things;Internet of Things,,2,,157,IEEE,22 Jul 2019,,,IEEE,IEEE Journals,,
Fog as a Service Technology,"Dynamic deployment, resource pooling, offloading, dynamic deployment","5, 17, 14, 5,",N. Chen; Y. Yang; T. Zhang; M. -T. Zhou; X. Luo; J. K. Zao,,IEEE Communications Magazine,18 Nov 2018,2018,56,11,95,101,"Fog computing has emerged as a promising solution for the IoT and next generation mobile networks. As an extension to cloud computing, it enables service provisioning along the continuum from the cloud to things to reduce latency and bandwidth demands, and empower end users in their vicinity. Such a cloud-to-thing service continuum requires full technology support in infrastructure, platform, software and service levels. This article proposes FA2ST and its architecture to underpin a multi-level system of fog computing services for end-to-end support of IoT applications. It presents the concept of FA2ST and describes its architecture, main features, a use case in a vertical industry, and a performance study.",1558-1896,,10.1109/MCOM.2017.1700465,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8469812,,Cloud computing;Internet of Things;Computer architecture;Edge computing;Task analysis;Bandwidth;Communication networks,cloud computing;Internet of Things;mobile computing;resource allocation,next generation mobile networks;cloud computing;service provisioning;cloud-to-thing service continuum;FA2ST;multilevel system;fog computing services;end-to-end support;IoT applications;fog as a service technology,,54,,15,,23 Sep 2018,,,IEEE,IEEE Magazines,,
Dynamic Bandwidth Slicing for Time-Critical IoT Data Streams in the Edge-Cloud Continuum,"Time critical application support, offloading, dynamic adaptation, QoS awareness","12, 14, 19, 5,",F. Habeeb; K. Alwasel; A. Noor; D. N. Jha; D. AlQattan; Y. Li; G. S. Aujla; T. Szydlo; R. Ranjan,,IEEE Transactions on Industrial Informatics,19 Sep 2022,2022,18,11,8017,8026,"Edge computing has gained momentum in recent years, as complementary to cloud computing, for supporting applications (e.g., industrial control systems) that require time-critical communication guarantees. While edge computing can provide immediate analysis of streaming data from Internet of Things devices, those devices lack computing capabilities to guarantee reasonable performance for time-critical applications. To alleviate this critical problem, the prevalent trend is to offload these data analytic tasks from the edge devices to the cloud. However, existing offloading approaches are static in nature as they are unable to adapt varying workload and network conditions. To handle these issues, we present a novel distributed and quality of services based multilevel queue traffic scheduling system that can undertake semiautomatic bandwidth slicing to process time-critical incoming traffic in the edge-cloud environments. Our developed system shows a great enhancement in latency and throughput as well as reduction in energy consumption for edge-cloud environments.",1941-0050,,10.1109/TII.2022.3169971,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762563,Bandwidth slicing;cloud;data stream;edge;Internet of Things (IoT);multiqueues;software-defined networking (SDN);time critical,Internet of Things;Cloud computing;Bandwidth;Quality of service;Microservice architectures;Ecosystems;Time factors,,,,,,29,IEEE,25 Apr 2022,,,IEEE,IEEE Journals,,
Enabling microservices management for Deep Learning applications across the Edge-Cloud Continuum,"Heterogeneity, edge intelligence, geographic distribution, time criticality","8, 6, 3, 4,12,",Z. Houmani; D. Balouek-Thomert; E. Caron; M. Parashar,,2021 IEEE 33rd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD),28 Dec 2021,2021,,,137,146,"Deep Learning has shifted the focus of traditional batch workflows to data-driven feature engineering on streaming data. In particular, the execution of Deep Learning workflows presents expectations of near-real-time results with user-defined acceptable accuracy. Meeting the objectives of such applications across heterogeneous resources located at the edge of the network, the core, and in-between requires managing trade-offs between the accuracy and the urgency of the results. However, current data analysis rarely manages the entire Deep Learning pipeline along the data path, making it complex for developers to implement strategies in realworld deployments. Driven by an object detection use case, this paper presents an architecture for time-critical Deep Learning workflows by providing a data-driven scheduling approach to distribute the pipeline across Edge to Cloud resources. Furthermore, it adopts a data management strategy that reduces the resolution of incoming data when potential trade-off optimizations are available. We illustrate the system's viability through a performance evaluation of the object detection use case on the Grid'5000 testbed. We demonstrate that in a multi-user scenario, with a standard frame rate of 25 frames per second, the system speed-up data analysis up to 54.4% compared to a Cloud-only-based scenario with an analysis accuracy higher than a fixed threshold.",2643-3001,978-1-6654-4301-2,10.1109/SBAC-PAD53543.2021.00025,"NSF(grant numbers:OAC 1640834,OAC 1835692,OCE 1745246); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651638,Cloud computing;Edge computing;Microservices;Task allocation;Real-time processing;Computing Continuum;Deep Learning,Deep learning;Data analysis;Image edge detection;Pipelines;Object detection;Computer architecture;Time factors,cloud computing;data analysis;deep learning (artificial intelligence);grid computing;resource allocation;scheduling,microservices management;edge-cloud continuum;traditional batch workflows;data-driven feature engineering;deep learning workflows;near-real-time results;user-defined acceptable accuracy;heterogeneous resources;data analysis;entire deep learning pipeline;data path;realworld deployments;object detection use case;data management strategy;potential trade-off optimizations;multiuser scenario;analysis accuracy;cloud-only-based scenario;cloud resources;time-critical deep learning workflows;deep learning applications,,,,35,IEEE,28 Dec 2021,,,IEEE,IEEE Conferences,,
To Offload or Not? An Analysis of Big Data Offloading Strategies from Edge to Cloud,"Offloading, dynamic orchestration","14, 5, ",R. Singh; J. Kovacs; T. Kiss,,2022 IEEE World AI IoT Congress (AIIoT),13 Jul 2022,2022,,,46,52,"Large reductions in completion times can result from transfer of Big Data tasks from edge nodes to cloud resources, which can reduce the completion times by up to 97 % and meet client deadlines for computational tasks with responsive and agile solutions. Using scientific programs of varying computational complexity to model resource-intensive tasks, we demonstrate that the task complexity of the computational jobs, the Wide Area Network (WAN) speed and the potential overload of edge servers (as reflected by CPU workloads) are crucial for achieving total reductions in task completion time edge-cloud orchestrators are situated in edge nodes. With continuous access to the parameters of Wireless Local Area Network (WLAN) speed (for data exchanges between client and edge resources), WAN speed (for data exchanges between edge and cloud resources) edge server CPU workload and the complexities in Big Data analytics requirements, accurate edge-to-cloud offloading decisions can be made to minimise total task completion time by the use of cloud computing resources. This work supports the major research efforts have been recently made to develop novel resource orchestration solutions to flexibly link edge nodes with centralised cloud resources so as to maximise the efficiency with which such a continuum of resources can be accessed by users.",,978-1-6654-8453-4,10.1109/AIIoT54504.2022.9817276,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817276,Application-level orchestration;Cloud-to-Edge con-tinuum;Big Data analytics;WLAN;WAN;Computational complexity;Server workload,Wide area networks;Cloud computing;Wireless LAN;Computational modeling;Big Data;Servers;Task analysis,Big Data;cloud computing;computational complexity;data analysis;resource allocation;wide area networks;wireless LAN,offload;Big Data offloading strategies;completion times;Big Data tasks;edge nodes;client deadlines;computational tasks;responsive solutions;agile solutions;computational complexity;resource-intensive tasks;task complexity;computational jobs;Wide Area Network speed;edge servers;total reductions;task completion time edge-cloud orchestrators;Wireless Local Area Network speed;data exchanges;WAN speed;Big Data analytics requirements;edge-to-cloud offloading decisions;total task completion time;cloud computing resources;novel resource orchestration solutions;centralised cloud resources,,,,18,IEEE,13 Jul 2022,,,IEEE,IEEE Conferences,,
Service Placement for Real-Time Applications: Rate-Adaptation and Load-Balancing at the Network Edge,"Dynamic placement, real-time support, mobility support","5, 12, 13, ",S. Kassir; G. d. Veciana; N. Wang; X. Wang; P. Palacharla,,2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom),19 Aug 2020,2020,,,207,215,"Mobile Edge Computing may become a prevalent platform to support applications where mobile devices have limited compute, storage, energy and/or data privacy concerns. In this paper, we study the efficient provisioning and management of compute resources in the Edge-to-Cloud continuum for different types of real-time applications with timeliness requirements depending on application-level update rates and communication/compute delays. We begin by introducing a highly stylized network model allowing us to study the salient features of this problem including its sensitivity to compute vs. communication costs, application requirements, and traffic load variability. We then propose an online decentralized service placement algorithm, based on estimating network delays and adapting application update rates, which achieves high service availability. Our results exhibit how placement can be optimized and how a load-balancing strategy can achieve near-optimal service availability in large networks.",,978-1-7281-6550-9,10.1109/CSCloud-EdgeCom49738.2020.00044,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170993,Edge Computing;Fog Network Dimensioning;Rate Adaptation;Service Placement;Real-Time Applications,Cloud computing;Sensitivity;Multi-access edge computing;Conferences;Telecommunication traffic;Real-time systems;Mobile handsets,cloud computing;data privacy;mobile computing;radio networks;resource allocation;telecommunication traffic,real-time applications;rate-adaptation;network edge;Mobile Edge Computing;prevalent platform;mobile devices;efficient provisioning;Edge-to-Cloud continuum;timeliness requirements;application-level update rates;highly stylized network model;communication costs;application requirements;traffic load variability;online decentralized service placement algorithm;network delays;adapting application update rates;high service availability;load-balancing strategy;near-optimal service availability,,2,,40,,19 Aug 2020,,,IEEE,IEEE Conferences,,
Smart Schools: Using IoTs and Fog Computing to Predict Underperformance,"Layered structure, offloading, low latency, dynamic resource utilization","9,14, 12, 17, 5,",M. Sharaf,,2020 2nd International Conference on Computer and Information Sciences (ICCIS),24 Nov 2020,2020,,,1,6,"The existing centralized computing paradigm is no longer suitable to achieve the digital continuum in the ever-growing Internet of Things (IoTs). IoT-based applications and the data harvested by these smart objects require a design of a system model that can handle intensive data and provide suitable communication protocols. In this paper, we present a school attendance system that facilitates the usage and collaboration of the digital continuum in a manner that shuns high bandwidth consumption and big latency. This work has the following contributions: (a) offers a novel usage of IoTs and fog in the school absenteeism system. It promotes a transparent workload offloading among the digital continuum layers (IoTs, edge, HPC, big data, Artificial Intelligence (AI), cloud) using two famous protocols, MQTT and TCP; (b) presents a case study that utilizes the digital continuum to achieve a task of interest.",,978-1-7281-5467-1,10.1109/ICCIS49240.2020.9257689,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257689,IoT;HPC;cloud computing;edge computing;latency;machine learning,Cloud computing;Computational modeling;Edge computing;Servers;Data models;Protocols;Histograms,educational administrative data processing;Internet of Things;protocols,smart schools;predict underperformance;existing centralized computing paradigm;IoT-based applications;smart objects;system model;intensive data;suitable communication protocols;school attendance system;high bandwidth consumption;fog;school absenteeism system;digital continuum layers;big data,,,,37,IEEE,24 Nov 2020,,,IEEE,IEEE Conferences,,
Flow-Based Programming for IoT Leveraging Fog Computing,"Heterogeneity, on-demand resource provisioning, service autonomy, environment responsiveness","9, 17, 1, ",T. Szydlo; R. Brzoza-Woch; J. Sendorek; M. Windak; C. Gniady,,2017 IEEE 26th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE),10 Aug 2017,2017,,,74,79,"The number of devices connected to the Internet is constantly growing. They are interacting with each other and produce data that has to be processed. The increasing data volume generated by the IoT devices is well handled by the flow based programming where data is moved through the networks of processes. Limited resources of the devices are compensated by the clouds creating the continuum. Nevertheless, to increase responsiveness in IoT or optimize the network bandwidth it might be necessary to move some processing to the fog i.e. to the devices located closer to the data sources. Execution of data flow on the number of heterogeneous IoT devices is not trivial as they offer different computational resources. In the paper, the concept of data flow transformation in order to execute parts of it, closer to the sources of data, on the devices with constrained resources is presented.",,978-1-5386-1759-5,10.1109/WETICE.2017.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8003792,,Cloud computing;Edge computing;Programming;Sensors;Image color analysis;Data processing,cloud computing;data flow analysis;Internet of Things;resource allocation,flow-based programming;fog computing;cloud computing;network bandwidth optimization;IoT responsiveness;heterogeneous IoT devices;computational resources;data flow transformation;constrained resources,,13,,20,,10 Aug 2017,,,IEEE,IEEE Conferences,,
Energy-Aware Workload Allocation for Distributed Deep Neural Networks in Edge-Cloud Continuum,"Energy awareness, edge intelligence, multi-layer structure","7, 6, 9, ",Y. Jin; J. Xu; Y. Huan; Y. Yan; L. Zheng; Z. Zou,,2019 32nd IEEE International System-on-Chip Conference (SOCC),7 May 2020,2019,,,213,217,"This paper presents an energy-aware workload allocation framework for Distributed Deep Neural Networks (DNNs) in the Edge-Cloud continuum. As opposed to conventional approaches where the inference is performed in a standalone device, a computing-communication mode is proposed to distribute computing tasks of different layers of DNNs to different levels of the Edge-Cloud network to achieve the minimum energy cost per inference. The optimal exit layer (EL) can be determined where the intermediate data of the neural networks are transmitted to the higher level in the Edge-Cloud continuum. Case studies are illustrated for AlexNet and VGG-16 considering a set of DNN processors and wireless interfaces. Using the GPU GTX1080 with 22.8 GOPS/W and the WiFi with 10 nJ/bit transmission efficiency, the optimized energy consumption for AlexNet is estimated to be 0.016 J when the inference exits from the edge at the EL2 (Conv1) layer. For VGG-16, the optimal EL is EL1 with the minimum inference cost of 0.0482 J.",2164-1706,978-1-7281-3483-3,10.1109/SOCC46988.2019.1570554761,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9088011,,,cloud computing;distributed processing;energy consumption;graphics processing units;neural nets;power aware computing;wireless LAN,Distributed Deep Neural Networks;Edge-Cloud continuum;energy-aware workload allocation framework;DNNs;computing-communication mode;Edge-Cloud network;minimum energy cost;optimal exit layer;optimized energy consumption;minimum inference cost;energy 0.016 J;energy 0.0482 J,,2,,14,IEEE,7 May 2020,,,IEEE,IEEE Conferences,,
Future Opportunistic Fog/Edge Computational Models and their Limitations,"pervasive computing, edge AI, QoS improvement","4, 6, 19, ",S. Singla; N. K. Bhati; S. Aswath,,"Fog, Edge, and Pervasive Computing in Intelligent IoT Driven Applications",,2021,,,27,46,"The Internet‐of‐Things (IoT) is the possible future of the Internet, where everything will be connected. The IoT is required to interface with billions of devices and individuals to bring positive benefits to us all. With this advance, cloud computing, close to its edge, prepares perfect models, for instance, multi access edge computing (MEC) and cloudlets, are seen as promising responses for dealing with the large volume of security‐important and time‐sensitive data that is being created by the IoT. Studies have revealed that Fog/Edge Computing (FEC) based organizations will assume an essential role in expanding the cloud by means of go‐between organizations at the edge of the framework. Dimness/Edge Computing‐based IoT's (DECIoT) configure service organization provisioning near the Cloud‐to‐Things continuum, thus making it appropriate for key applications. Moreover, the proximity of fog/edge devices to where the data is created makes it extend the advantage partition, organization transport, and assurance. Edge and fog registering are closely related – both indicate the ability to process information closer to the requester/buyer to reduce idleness cost and improve client experience. Both can channel information before it “hits” a major information lake for further utilization, reducing the amount of information that can be handled. The essential idea of edge and fog processing is to move information rationale (basically around information approval/information sentence structure checks) to an external ring of capacities. In this chapter we review the difficulties and future directions to be investigated in the role of fog, edge and pervasive computing.",,9781119670094,10.1002/9781119670087.ch2,,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9292550.pdf&bkn=9292526&pdfType=chapter,,Organizations;Edge computing;Switches;Servers;Technological innovation;Security;Programming,,,,,,,,14 Dec 2020,,,IEEE,Wiley-IEEE Press eBook Chapters,,
Internet of Things: From Small- to Large-Scale Orchestration,"Autonomous components, continuum of scale, dynamic deployment","1, 9, 5,",C. Consel; M. Kabáč,,2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS),17 Jul 2017,2017,,,1748,1755,"The domain of Internet of Things (IoT) is rapidly expanding beyond research, and becoming a major industrial market with such stakeholders as major manufacturers of chips and connected entities (i.e., things), and fast-growing operators of wide-area networks. Importantly, this emerging domain is driven by applications that leverage an IoT infrastructure to provide users with innovative, high-value services. IoT infrastructures range from small scale (e.g., homes and personal health) to large scale (e.g., cities and transportation systems). In this paper, we argue that there is a continuum between orchestrating connected entities in the small and in the large. We propose a unified approach to application development, which covers this spectrum. To do so, we examine the requirements for orchestrating connected entities and address them with domainspecific design concepts. We then show how to map these design concepts into dedicated programming patterns and runtime mechanisms. Our work revolves around domain-specific concepts and notations, integrated into a tool-based design methodology and dedicated to develop IoT applications. We have applied our work across a spectrum of infrastructure sizes, ranging from an automated pilot in avionics, to an assisted living platform for the home of seniors, to a parking management system in a smart city.",1063-6927,978-1-5386-1792-2,10.1109/ICDCS.2017.314,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7980112,Internet of things;domain-specific languages;programming frameworks;MapReduce;orchestration,Monitoring;Programming;Aerospace electronics;Sensor phenomena and characterization;Internet of Things;Urban areas,Internet of Things;object-oriented programming;smart cities,Internet of Things;small-scale orchestration;large-scale orchestration;wide-area network;IoT infrastructure;innovative high-value service;personal health;transportation system;connected entity orchestration;domain-specific design concept;programming patterns;runtime mechanisms;tool-based design;IoT application development;infrastructure size;automated pilot;avionics;assisted living platform;seniors;parking management system;smart city,,6,,20,,17 Jul 2017,,,IEEE,IEEE Conferences,,
Analysis on data deduplication techniques of storage of big data in cloud,"High resource availability, low latency, geographic diustribution","27, 12, 4,",K. Vijayalakshmi; V. Jayalakshmi,,2021 5th International Conference on Computing Methodologies and Communication (ICCMC),6 May 2021,2021,,,976,983,"As nowadays, many devices are connected to the internet (Thing continuum), and many businesses deal with a huge amount of data, digital data growth is exponentially increased. Cloud computing is the optimal technology that provides many computing resources, especially storage for Big data. Cloud offers the best storage management to back up the big data from IoT, business, enterprise, or government. All data owners want the protection of their own data, so they encrypt the data before outsourcing data in clouds. As many users avail cloud storage, different users may outsource the same data with different encryption techniques, and it results in data duplication or data redundancy. Although cloud computing offers a huge amount of storage space, data duplication decreases the efficiency and performance of cloud storage, and also it results in poor data management and the requirement of high bandwidth. The deduplication technique is used to manage data duplication in clouds. Although there are some deduplication approaches used to avoid data redundancy, still they have lack efficiency. The main aim of this paper is to obtain sufficient knowledge and a good idea about deduplication techniques by surveying existing approaches and this work may help the researcher and practitioner for their future research in developing efficient cloud storage management techniques.",,978-1-6654-0360-3,10.1109/ICCMC51019.2021.9418445,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418445,Big data;Cloud computing;Cloud storage;Data deduplication;Data duplication;data management;IoT,Cloud computing;Storage management;Redundancy;Government;Memory;Bandwidth;Big Data,cloud computing;cryptography;outsourcing;storage management,data redundancy;storage space;data duplication;poor data management;deduplication technique;efficient cloud storage management techniques;data deduplication techniques;big data;digital data growth;cloud computing;cloud offers;data owners;outsourcing data;users avail cloud storage;different encryption techniques,,,,23,,6 May 2021,,,IEEE,IEEE Conferences,,
Pricing Tradeoffs for Data Analytics in Fog–Cloud Scenarios,"Cross-level cooperation, QoS management, cost management","2, 19, 20, ",Y. Ruan; L. Zheng; M. Gorlatova; M. Chiang; C. Joe‐Wong,,"Fog and Fogonomics: Challenges and Practices of Fog Computing, Communication, Networking, Strategy, and Economics",,2020,,,83,106,"Fog computing represents a generalization of traditional cloud computing, in which application functionality resides at a local device and a remote cloud server. This chapter presents an initial survey of fogonomics, using a case study of distributed data processing to illustrate its research challenges. In particular, it demonstrates the trade‐off between balancing quality‐of‐service and service cost when distributing application tasks between cloud and edge devices, given a set of service prices. Applications utilizing fog architectures will require access to both computing devices at different levels of the cloud‐to‐things continuum and network bandwidth to connect these devices together. The chapter discusses the economics faced by fog applications today. It provides an overview of typical fog application architectures on which economic markets are constructed. The chapter also illustrates how price schemes impact the design of fog applications through the case study.",,9781119501107,10.1002/9781119501121.ch4,,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9215562.pdf&bkn=9215548&pdfType=chapter,,Cloud computing;Pricing;Economics;Edge computing;Servers;Computer architecture;Sensors,,,,1,,,,7 Oct 2020,,,Wiley,Wiley Telecom eBook Chapters,,
Application of Fog Architecture Based on Multi-agent Mechanism in CPPS,"Low latency, reliability, self-adaptation, multi-agent, geographically distributed, resource management","12, 16, 5, 1, 3, 17,",H. Wang; Q. Wang; Y. Li; G. Chen; Y. Tang,,2018 2nd IEEE Conference on Energy Internet and Energy System Integration (EI2),20 Dec 2018,2018,,,1,6,"In the cyber-physic power system (CPPS) scenario, an increasing number of new devices, such as large-scale electric meters, embedded controllers and powerful computing devices are introduced into the power system. However, the architecture of present power system limits the seamless integration of the information system and physical systems. In this paper, a decentralized CPPS-fog architecture is proposed to address this issue. The proposed architecture distributes computing, communication storage, and control these services to the edge network along the cloud-to-thing continuum while the latter is commonly used in the smart grid. By applying the new architecture to the power system, the intelligence resources of the power system are effectively allocated to the parts closer to end users. Moreover, the realtime monitoring, on-line simulation, information integration, large-scale distributed control, and information security protection are easily achieved. The feasibility and advantages of the CPPS-fog architecture are demonstrated by the application in an island micro CPPS grid project.",,978-1-5386-8549-5,10.1109/EI2.2018.8582467,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8582467,cyber-physic power system (CPPS);fog;architecture;smart grid,Computer architecture;Cloud computing;Data centers;Task analysis;Companies;Smart grids,cloud computing;cyber-physical systems;distributed power generation;multi-agent systems;power engineering computing;security of data;smart power grids;software architecture,edge network;cloud-to-thing continuum;intelligence resources;island microCPPS grid project;multiagent mechanism;information security protection;cyber-physic power system scenario;decentralized CPPS-fog architecture;physical systems;information system,,1,,12,,20 Dec 2018,,,IEEE,IEEE Conferences,,
Managing the Resource Continuum in a Real Video Surveillance Scenario,"real-time support, dynamic resource management, energy consumption optimization","12, 5, 17, 7,",F. Sciamanna; M. Zanella; G. Massari; W. Fornaciari,,2021 24th Euromicro Conference on Digital System Design (DSD),11 Oct 2021,2021,,,58,61,"Over the last years, the number of IoT devices has grown exponentially. Thus, Fog and Edge computing move part of the computation closer to data sources, exploiting interconnected devices in a computing continuum viewpoint. These devices are heterogeneous in terms of performance, features, and capabilities, requiring proper programming models and run-time management layers. This work presents a first version of the BarMan open-source framework. We developed a run-time task allocation policy to maximize application performance and through an experimental evaluation performed on a real cluster, we evaluated different execution scenarios. The results show an improvement up to 66% on the frame processing latency with respect to a monolithic solution.",,978-1-6654-2703-6,10.1109/DSD53832.2021.00018,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9556331,Fog Computing;Resource Management;Programming model;Task allocation strategy,Performance evaluation;Digital systems;Computational modeling;Programming;Video surveillance;Resource management;Task analysis,Internet of Things;multiprocessing systems;real-time systems;resource allocation;video surveillance,Edge computing move part;data sources;interconnected devices;computing continuum viewpoint;proper programming models;run-time management layers;BarMan open-source framework;run-time task allocation policy;application performance;experimental evaluation;different execution scenarios;resource continuum;video surveillance scenario;IoT devices;Fog,,,,21,,11 Oct 2021,,,IEEE,IEEE Conferences,,
Delay-Aware Task Offloading in Shared Fog Networks,"Offloading, real-time support, geo-distribution, heterogeneous hardware","14, 12, 3, 8,",Y. Jiang; D. H. K. Tsang,,IEEE Internet of Things Journal,16 Jan 2019,2018,5,6,4945,4956,"Offloading computation tasks from resource-poor end devices to powerful backend clouds has become a prevalent solution thanks to the rapid development of cloud computing. However, modern Internet of Things applications, such as augmented reality and real-time monitoring, bring stringent delay requirements to the computation tasks in the device-to-computing-facility communications. To better accommodate the delay requirements of the computation tasks, the recently proposed fog computing architecture suggests that these computation tasks can be extensively offloaded to the distributed computation facilities along the cloud-to-things continuum. These computation facilities, including central clouds and the computation facilities standing at the network edge, jointly form an overlay network, named a fog network, to provide fog computing services for end devices. This paper targets a practical and efficient scheme to schedule tasks with heterogeneous delay sensitivities in a shared fog network. A mathematical model is first constructed to capture the major characteristics of a fog network. The model enforces lexicographic max–min fairness, an enhanced metric compared to conventional max–min fairness. The task offloading problem is modeled as an integer nonlinear program. An efficient and exact solution method is proposed based on problem-specific analysis. Finally, synthesized-trace-driven simulations demonstrate the efficacy of our proposed offloading scheme.",2327-4662,,10.1109/JIOT.2018.2880250,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8527523,Fog computing;optimization;resource allocation,Task analysis;Delays;Cloud computing;Edge computing;Mathematical model;Resource management,,,,15,,31,IEEE,8 Nov 2018,,,IEEE,IEEE Journals,,
A Case Study of an Organizational Continuum of a Technological Platform in a Japanese Accounting Cloud Service,Not about ECC,,Y. Mizuno; N. Odake,,2017 Portland International Conference on Management of Engineering and Technology (PICMET),30 Nov 2017,2017,,,1,11,"The purpose of this study is to clarify an organizational continuum of a technological platform development in a Japanese accounting cloud service. The authors continuously have been studying an accounting cloud service, which adopts two-sided markets structure and freemium business model on a core and periphery platform with modular designs. As the results of our case study, the authors obtain three findings. First, the Japanese accounting cloud service, which runs its business with regional banks in retail banking, has been exploiting its platform into partners' customers. Second, the accounting cloud service has been building up from a supplychain platform to an industrial platform in retail banking in four years since its entrepreneurship. Third, the accounting cloud service has been transforming its cloud-to-cloud service connections from weak-tied interfaces developed by other companies to its own strong-tied interfaces. Therefore, startingup cloud service providers should not only utilize weak-tied interfaces to invite two-sides onto its platform to establish a structural hole within its two-sided markets structure, but also should develop its own strong-tied interfaces and indirect ties to tighten upon its two-sided markets structure to realize values buried in its cloud ecosystem.",,978-1-890843-36-6,10.23919/PICMET.2017.8125311,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125311,,Cloud computing;Technological innovation;Ecosystems;Companies;Banking,banking;cloud computing;financial management;innovation management;organisational aspects,retail banking;cloud-to-cloud service connections;startingup cloud service providers;two-sided markets structure;cloud ecosystem;organizational continuum;japanese accounting cloud service;technological platform development;time 4.0 year,,,,31,,30 Nov 2017,,,IEEE,IEEE Conferences,,
A Methodology and Simulation-based Toolchain for Estimating Deployment Performance of Smart Collective Services at the Edge,"Heterogeneity, dynamicity, uncertainty, use of AI, resource management, QoS targets","8, 5, 18, 6, 17, 19,",R. Casadei; G. Fortino; D. Pianini; A. Placuzzi; C. Savaglio; M. Viroli,,IEEE Internet of Things Journal,,2022,PP,99,1,1,"Research trends are pushing artificial intelligence (AI) across the IoT-Edge-Fog-Cloud continuum, to enable effective data analytics, decision making, as well as efficient use of resources for QoS targets. Approaches for collective adaptive systems engineering, such as aggregate computing, provide declarative programming models and tools for dealing with the uncertainty and the complexity that may arise from scale, heterogeneity, and dynamicity. Crucially, aggregate computing architecture allows for “pulverisation”: applications can be decomposed into many deployable micro-modules that can be spread across the ICT infrastructure, thus allowing multiple potential deployment configurations for the same application logic. This article studies the deployment architecture of aggregate-based edge services and its implications in terms of performance and cost. The goal is to provide methodological guidelines and a model-based toolchain for the generation and simulation-based evaluation of potential deployments. First, we address this subject methodologically by proposing an approach based on deployment code generators and a simulation phase whose obtained solutions are assessed with respect to their performance and costs. We then tailor this approach to aggregate computing applications deployed onto an IoT-Edge-Fog-Cloud infrastructure, and we develop a corresponding toolchain based on Protelis and EdgeCloudSim. Finally, we evaluate the approach and tools through a case study of edge multimedia streaming, where the edge ecosystem exhibits intelligence by self-organising into clusters to promote load-balancing in large-scale dynamic settings.",2327-4662,,10.1109/JIOT.2022.3172470,"Ministero dellIstruzione dellUniversit e della Ricerca(grant numbers:PRIN 2017 N. 2017KRC7KT ""Fluidware""); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768117,Cyber-Physical Systems;Mobile and Ubiquitous Systems;Service Middleware and Platform;Cloud Services;Edge Intelligence;Collective Services;Pulverisable Architectures;Deployment methodology;Simulation.,Aggregates;Computational modeling;Costs;Internet of Things;Programming;Computer architecture;Adaptive systems,,,,,,,CCBY,4 May 2022,,,IEEE,IEEE Early Access Articles,,
Towards Low-Latency Service Delivery in a Continuum of Virtual Resources: State-of-the-Art and Research Directions,"Edge intelligence, low latencies, NFV","6, 12,22,",J. Santos; T. Wauters; B. Volckaert; F. De Turck,,IEEE Communications Surveys & Tutorials,19 Nov 2021,2021,23,4,2557,2589,"The advent of softwarized networks has enabled the deployment of chains of virtual network and service components on computational resources from the cloud up to the edge, creating a continuum of virtual resources. The next generation of low latency applications (e.g., Virtual Reality (VR), autonomous cars) adds even more stringent requirements to the infrastructure, calling for considerable advancements towards cloud-native micro-service-based architectures. This article presents a comprehensive survey on ongoing research aiming to effectively support low latency services throughout their execution lifetime in next-generation networks. The current state-of-the-art is critically reviewed to identify the most promising trends that will strongly impact the full applicability and high performance of low latency services. This article proposes a taxonomy as well as specific evaluation criteria to classify research across different domains addressing low latency service delivery. Current architectural paradigms such as Multi-access Edge Computing (MEC) and Fog Computing (FC) alongside novel trends on communication networks are discussed. Among these, the integration of Machine Learning (ML) and Artificial intelligence (AI) is introduced as a key research field in current literature towards autonomous network management. A discussion on open challenges and future research directions on low-latency service delivery leads to the conclusion, offering lessons learned and prospects on emerging use cases such as Extended Reality (XR), in which novel trends will play a major role.",1553-877X,,10.1109/COMST.2021.3095358,Scientific Research-Flanders (FWO-V) through the Project “Intelligent Dense and Longe Range IoT Networks (IDEAL-IoT)”(grant numbers:S004017N);,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476028,Low latency;next-generation networks;cloud-native;autonomous networks;orchestration;5G/6G,Tutorials;Next generation networking;Taxonomy;Market research;5G mobile communication;Computer architecture;Cloud computing,artificial intelligence;cloud computing;learning (artificial intelligence);mobile computing;service-oriented architecture;telecommunication network management;virtual reality,towards low-latency service delivery;virtual resources;softwarized networks;virtual network;service components;computational resources;low latency applications;Virtual Reality;cloud-native microservice-based architectures;low latency services;next-generation networks;low latency service delivery;current architectural paradigms;communication networks;key research field;autonomous network management,,6,,189,IEEE,7 Jul 2021,,,IEEE,IEEE Journals,,
Optimising Cost vs Accuracy of Decentralised Analytics in Fog Computing Environments,"Decentralized AI, distributed training, cost management, cooperative devices","6, 20, 2, ",L. Valerio; A. Passarella; M. Conti,,IEEE Transactions on Network Science and Engineering,27 Jun 2022,2022,9,4,1986,2002,"The exponential growth of devices and data at the edges of the Internet is rising scalability and privacy concerns on approaches based exclusively on remote cloud platforms. Data gravity, a fundamental concept in Fog Computing, points towards decentralisation of computation for data analysis, as a viable alternative to address those concerns. Decentralising AI tasks on several cooperative devices means identifying the optimal set of locations or Collection Points (CP for short) to use, in the continuum between full centralisation (i.e., all data on a single device) and full decentralisation (i.e., data on source locations). We propose an analytical framework able to find the optimal operating point in this continuum, linking the accuracy of the learning task with the corresponding network and computational cost for moving data and running the distributed training at the CPs. We show through simulations that the model accurately predicts the optimal trade-off, quite often an intermediate point between full centralisation and full decentralisation, showing also a significant cost saving w.r.t. both of them. Finally, the analytical model admits closed-form or numeric solutions, making it not only a performance evaluation instrument but also a design tool to configure a given distributed learning task optimally before its deployment.",2327-4697,,10.1109/TNSE.2021.3101986,"SAI:Social Explainable AI(grant numbers:CHIST-ERA-19-XAI-010); HumanE AI Network(grant numbers:#952026); SoBigData++(grant numbers:#871042); Operational Knowledge from Insights and Analytics on Industrial Data(grant numbers:MIUR PON OK-INSAID,ARS01_00917); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507297,Distributed machine learning;DSVRG;optimal configuration;edge computing.,Data models;Computational modeling;Analytical models;Distributed databases;Task analysis;Cloud computing;Data analysis,cloud computing;data analysis;data privacy;learning (artificial intelligence);software cost estimation,source location;computational cost;distributed training;distributed learning;decentralised analytics;data privacy;remote cloud platforms;data gravity;data analysis;fog computing;data location;collection points;AI decentralisation,,,,43,IEEE,4 Aug 2021,,,IEEE,IEEE Journals,,
Teaching Experiences in Academia to Understand the Impact of Smart Cities,"AI application, mobility support, integration into society, energy efficiency","6, 13, 25, 7,",J. J. Gomez-Sanz; E. Alba; J. M. Fernandez-Gũell,,NA,NA,IEEE Internet of Things Magazine,6 Nov 2019,2019,2,2,20,24,"One of the key technologies transforming cities into smart cities is the Internet of Things or IoT. Nevertheless, there are reasons to believe that third parties, such as authorities, citizens, and companies, do not really understand what IoT and other enabling technologies bring to them. Instead, they live in a continuum of delivering vertical (final services) one after another where technology is the driver. As higher education practitioners, we have the responsibility of training future professionals so that they can explore and explain what smart cities bring in a more citizen-centric way. This article accounts experiences in teaching and research aimed at this goal. We summarize the expertise of three universities in Spain: the School of Urban Studies of the Politechnic University of Madrid, the Computer Science School of the Complutense University of Madrid, and the University of Malaga. This view is complemented with a discussion of other higher education training options focused on smart cities. The analysis of these higher education titles (degrees and Master's) is that they are highly influenced by technology. Frequently, teaching staff and/or course attendants have a technical background. More social sciences involvement is necessary to have a broader perspective on smart cities.",2576-3199,,10.1109/IOTM.001.1900015,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892764,,Smart cities;Training;Internet of Things;Complexity theory,computer aided instruction;computer science education;educational courses;educational institutions;further education;Internet of Things;smart cities;teaching,computer science school;complutense university of Madrid;politechnic university of Madrid;Internet of things;higher education training options;IoT;smart cities;teaching experiences,,,,20,IEEE,6 Nov 2019,,,IEEE,IEEE Magazines
Outsourced Data Integrity Checking with Practical Key Update in Edge-Cloud Resilient Networks,"Cross-layer collaboration, QoS management, security challenges","2, 19, 15,",L. Wang; Y. Li; Q. Yu; Y. Yu,,IEEE Wireless Communications,16 Aug 2022,2022,29,3,56,62,"The edge-cloud continuum is an advanced paradigm for cloud computing, which brings data storage and compute power closer to users or devices, and as a result, eliminates lag time and saves bandwidth. However, this new paradigm is harsh for secure storage and computation due to the separation of data ownership and control. Data security, especially outsourced data integrity in the edge-cloud resilient network, becomes one of the most fundamental challenges. To check the outsourced data integrity and address the efficient key update issue in this scenario, in this article, we propose a framework of outsourced data integrity checking with a practical key update in the edge-cloud resilient network. We first review the existing outsourced data integrity checking algorithms and then put forward a potential solution to achieving outsourced data integrity checking with a practical key update, which is composed of three phases, namely key request and update, local data upload, and outsourced data integrity auditing. We implement a prototype system for our proposal as well, which demonstrates its practicality.",1558-0687,,10.1109/MWC.002.2100597,"National Natural Science Foundation of China(grant numbers:62102209,61872229,U19B2021); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857807,,Cloud computing;Protocols;Data integrity;Data security;Prototypes;Memory;Data models;Outsourcing;Energy storage,cloud computing;computer network security;data integrity;outsourcing,edge-cloud resilient network;edge-cloud continuum;cloud computing;data storage;secure storage;data ownership;data security;outsourced data integrity auditing;outsourced data integrity checking,,,,15,IEEE,16 Aug 2022,,,IEEE,IEEE Magazines,,
When Social Sensing Meets Edge Computing: Vision and Challenges,"Social sensing, edge intelligence, ubiquity, individual device ownership","25, 6, 8, 4,",D. Zhang; N. Vance; D. Wang,,2019 28th International Conference on Computer Communication and Networks (ICCCN),26 Sep 2019,2019,,,1,9,"This paper overviews the state of the art, research challenges, and future opportunities in an emerging research direction: Social Sensing based Edge Computing (SSEC). Social sensing has emerged as a new sensing application paradigm where measurements about the physical world are collected from humans or from devices on their behalf. The advent of edge computing pushes the frontier of computation, service, and data along the cloud-to-things continuum. The merging of these two technical trends generates a set of new research challenges that need to be addressed. In this paper, we first define the new SSEC paradigm that is motivated by a few underlying technology trends. We then present a few representative real-world case studies of SSEC applications and several key research challenges that exist in those applications. Finally, we envision a few exciting research directions in future SSEC. We hope this paper will stimulate discussions of this emerging research direction in the community.",2637-9430,978-1-7281-1856-7,10.1109/ICCCN.2019.8847174,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847174,,Sensors;Servers;Edge computing;Task analysis;Image edge detection;Performance evaluation;Cloud computing,cloud computing;social networking (online),social sensing;edge computing;sensing application paradigm;SSEC paradigm;SSEC applications;research direction;cloud-to-things continuum,,14,,51,,26 Sep 2019,,,IEEE,IEEE Conferences,,
DEEP: A Vertical-Oriented Intelligent and Automated Platform for the Edge and Fog,"Simplified interfaces, edge intelligence, extreme heterogeneity, distributed infrastructure","30, 6, 8, 4,",C. Guimarães; M. Groshev; L. Cominardi; A. Zabala; L. M. Contreras; S. T. Talat; C. Zhang; S. Hazra; A. Mourad; A. de la Oliva,,IEEE Communications Magazine,5 Jul 2021,2021,59,6,66,72,"The fifth generation (5G) of mobile communications introduces improvements on many fronts when compared to its previous generations. Besides the performance enhancements and new advances in radio technologies, it also integrates other technological domains, such as cloud-to-things continuum and artificial intelligence. In this work, the 5G-DIVE Elastic Edge Platform (DEEP) is proposed as the linking piece for the integration of these technological domains, making available an intelligent edge and fog 5G end-to-end solution. This solution brings numerous benefits to vertical industries by enabling streamlined, abstracted, and automated management of their vertical services, thus contributing to the introduction of novel services, cost savings, and improved time to market. Preliminary validation of the proposed platform is performed through a proof of concept, along with a qualitative analysis of its benefits for Industry 4.0 and autonomous drone scouting vertical industries.",1558-1896,,10.1109/MCOM.001.2000986,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9475161,,Edge computing;5G mobile communication;Time to market;Artificial intelligence;Drones,5G mobile communication,technological domains;fog 5G;automated management;vertical services;DEEP;mobile communications;performance enhancements;radio technologies;cloud-to-things continuum;artificial intelligence;linking piece;elastic edge platform;intelligent edge;vertical oriented intelligent;automated platform;5G communications,,1,,15,IEEE,5 Jul 2021,,,IEEE,IEEE Magazines,,
Coding the Continuum,"Fast networks, blending boundaries between layers, disintegrating computer systems","12, 9, 2, 31,",I. Foster,,2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2 Sep 2019,2019,,,1,1,"In 2001, as early high-speed networks were deployed, George Gilder observed that “when the network is as fast as the computer's internal links, the machine disintegrates across the net into a set of special purpose appliances.” Two decades later, our networks are 1,000 times faster, our appliances are increasingly specialized, and our computer systems are indeed disintegrating. As hardware acceleration overcomes speed-of-light delays, time and space merge into a computing continuum. Familiar questions like “where should I compute,” “for what workloads should I design computers,” and ""where should I place my computers” seem to allow for a myriad of new answers that are exhilarating but also daunting. Are there concepts that can help guide us as we design applications and computer systems in a world that is untethered from familiar landmarks like center, cloud, edge? I propose some ideas and report on experiments in coding the continuum.",1530-2075,978-1-7281-1246-6,10.1109/IPDPS.2019.00011,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820775,,Computer science;Encoding;Cloud computing;Data science;Distributed processing;High-speed networks;Hardware acceleration,cloud computing,computing continuum;internal links;speed-of-light delays;high-speed networks;computer systems,,1,,0,,2 Sep 2019,,,IEEE,IEEE Conferences,,
Special issue on fog networks - Call for Papers,"Hierarhical architectures, flexible deployment, offloading, distributed data processing, security and privacy issues","9, 5, 14, 4, 15,",,,Journal of Communications and Networks,30 Nov 2017,2017,19,5,540,540,"Fog computing as an extension of cloud computing is able to deploy data storage, computing and communication, control and management along the cloud to things continuum. From a systematic perspective, fog networks provide a distributed computing system with a hierarchical topology. Fog networks aim at meeting stringent latency requirements, reducing power consumption of end devices, providing real-time data processing and control with localized computing resources, and decreasing the burden of backhaul traffic to centralized data centers. However, in the era of fog computing and networks, we need to rethink about end-to-end network architecture, fog-enabled service management mechanisms, computing offloading and task allocation among fog-cloud or fog-fog nodes, context-aware computing and communication tradeoff analysis, fogonomics and operational models, and scalability and security issues. The objective of this special issue is to solicit original contributions that demonstrate and explore current advances in various aspects of fog computing and networks, including but not limited to:",1976-5541,,10.1109/JCN.2017.000086,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8120254,,Edge computing;Peer-to-peer computing;Cloud computing;Data processing;Network architecture;Resource management,,,,,,,,30 Nov 2017,,,KICS,KICS Journals,,
Big Data Pipeline Scheduling and Adaptation on the Computing Continuum,"on-demand resource provisioning, extremely low latency, high performance, self-adaptivity","17, 12, 32, 5,",D. Kimovski; C. Bauer; N. Mehran; R. Prodan,,"2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",10 Aug 2022,2022,,,1153,1158,"The Computing Continuum, covering Cloud, Fog, and Edge systems, promises to provide on-demand resource-as-a-service for Internet applications with diverse requirements, ranging from extremely low latency to high-performance processing. However, eminent challenges in automating the resources man-agement of Big Data pipelines across the Computing Continuum remain. The resource management and adaptation for Big Data pipelines across the Computing Continuum require significant research effort, as the current data processing pipelines are dynamic. In contrast, traditional resource management strategies are static, leading to inefficient pipeline scheduling and overly complex process deployment. To address these needs, we propose in this work a scheduling and adaptation approach implemented as a software tool to lower the technological barriers to the management of Big Data pipelines over the Computing Continuum. The approach separates the static scheduling from the run-time execution, em-powering domain experts with little infrastructure and software knowledge to take an active part in the Big Data pipeline adaptation. We conduct a feasibility study using a digital healthcare use case to validate our approach. We illustrate concrete scenarios supported by demonstrating how the scheduling and adaptation tool and its implementation automate the management of the lifecycle of a remote patient monitoring, treatment, and care pipeline.",0730-3157,978-1-6654-8810-5,10.1109/COMPSAC54236.2022.00181,Horizon 2020;,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842650,Scheduling;Adaptation;Computing Continuum;Fog and Edge computing;Resources management,Patient monitoring;Processor scheduling;Software as a service;Big Data;Electronic healthcare;Resource management;Task analysis,Big Data;data handling;health care;Internet;multiprocessing systems;patient monitoring;pipeline processing;resource allocation;scheduling;telemedicine;ubiquitous computing,Big Data pipeline scheduling;Computing Continuum;on-demand resource-as-a-service;resources man-agement;current data processing pipelines;traditional resource management strategies;inefficient pipeline scheduling;Big Data pipeline adaptation,,,,14,IEEE,10 Aug 2022,,,IEEE,IEEE Conferences,,
Cross-Layer Soft-Error Resilience Analysis of Computing Systems,"high resilience, layered structure, holistic design","16, 9, 33,",A. Bosio; R. Canal; S. Di Carlo; D. Gizopoulos; A. Savino,,2020 50th Annual IEEE-IFIP International Conference on Dependable Systems and Networks-Supplemental Volume (DSN-S),5 Aug 2020,2020,,,79,79,"In a world with computation at the epicenter of every activity, computing systems must be highly resilient to errors even if miniaturization makes the underlying hardware unreliable. Techniques able to guarantee high reliability are associated to high costs. Early resilience analysis has the potential to support informed design decisions to maximize system-level reliability while minimizing the associated costs. This tutorial focuses on early cross-layer (hardware and software) resilience analysis considering the full computing continuum (from IoT/CPS to HPC applications) with emphasis on soft errors.",,978-1-7281-7260-6,10.1109/DSN-S50200.2020.00042,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159134,,Hardware;Resilience;Tutorials;Circuit faults;Software reliability;Reliability engineering,Internet of Things;parallel processing;power aware computing,soft errors;computing continuum;associated costs;system-level reliability;informed design decisions;high reliability;underlying hardware unreliable;computing systems;cross-layer soft-error resilience analysis,,,,2,,5 Aug 2020,,,IEEE,IEEE Conferences,,
Mobile Continuum: Necessity or Addiction- A Review,"Negative impact on mental health, addictiveness","34,",K. K. Ravulakollu; M. Chhabra; B. Sharan; R. Agarwal; R. Dewan; M. Goyal,,2022 9th International Conference on Computing for Sustainable Global Development (INDIACom),2 May 2022,2022,,,585,589,"Mobile Cell phones are essential for many young people; however, such devices can adversely affect their mental health and well-being. The rapid development of mobile technology offers a choice of high-end options and improved immobility, which will lead to an increase in the prevalence of mobile device use, especially among young people. They usually develop an attachment to mobile phones, seek closeness to mobile phones, and experience stress during separation. In the Asian country alone, about 600 million sensitive phone users will be active by early 2021. By the end of 2018, it is predicted that 530 million people in India will be smartphone users. Mobile addiction problems are growing at associate around the world at an alarming rate. Problems due to mobile phone addiction like sleep disturbance, anxiety, stress, and, to a lesser extent, and depression require immediate action. In this paper, several symptoms, effects, and causes of smartphone addiction are summarized.",,978-93-80544-44-1,10.23919/INDIACom54597.2022.9763139,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763139,Mobile phone addiction;Social Networking services;internet addiction;Addictive Behavior;use duration;health problems;depression;stress,Cellular phones;Sociology;Asia;Anxiety disorders;Entertainment industry;Mental health;Depression,smart phones,mobile continuum;smartphone addiction;mobile cell phone addiction problems;India,,,,15,,2 May 2022,,,IEEE,IEEE Conferences,,
XR in the 6G Post‐Smartphone Era,"Cross-reality environments, spatial and temporal non-locality","35, 36,",M. Maier; A. Ebrahimzadeh,,NA,Toward 6G: A New Era of Convergence,,2021,,,167,182,"In this chapter, the authors elaborate on how the Internet of No Things with its underlying human‐intended services may serve as a useful stepping stone toward realizing the far‐reaching vision of future 6G networks, ushering in the 6G post‐smartphone era. After briefly reviewing the 6G vision, they explain the reality–virtuality continuum in more detail and introduce the so‐called Multiverse for the design of advanced extended reality experiences, ranging from conventional virtual reality to more sophisticated cross‐reality environments known as third spaces. The authors then elaborate on the recently emerging invisible‐to‐visible technology concept, which we use together with other key enabling network technologies to tie both online and offline worlds closer together in an Internet of No Things and make it “see the invisible” through the awareness of nonlocal events in space and time.",,9781119658030,10.1002/9781119658054.ch7,,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9295207.pdf&bkn=9295055&pdfType=chapter,,6G mobile communication;X reality;Tactile Internet;5G mobile communication;Wireless communication;Maintenance engineering;Extended reality,,,,,,,,15 Dec 2020,,,IEEE,Wiley-IEEE Press eBook Chapters,
The Quantified Self and Mobile Health Applications: From Information and Communication Sciences to Social Innovation by Design,"Contemplative computing, calm technology and the attentive environment","37, 38, 39,",N. Bouha&iuml;; I. Saleh,,NA,Internet of Things: Evolutions and Innovations,,2018,,,139,168,"This chapter reviews the definition of certain terms related to the Quantified Self and mobile health (m‐health) in order to characterize the information technologies used by Chris Dancy. It presents the results of the selective analysis, emphasizing Chris Dancy's transformation. The chapter then analyzes the mobile applications used by Chris Dancy by exploring both information design and data‐visualization. Chris Dancy's vision of interaction design oriented toward contemplative computing, calm technology and the attentive environment falls within the continuum of Mark Weiser's ubiquitous computing project. Chris Dancy's experience seems to crystallize an emerging trend in the contemporary era, in which the relationship to a world mediated by interfaces is generalized, while the interfaces invisibilize into the environment. Interaction design's anthropological approach can contribute to the development of a critical reflection on the dominant models of interaction design only focused on technological or economic innovation.",,9781119476535,10.1002/9781119427391.ch6,,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=8607866.pdf&bkn=8607852&pdfType=chapter,,Information technology;Medical services;Internet of Things;Technological innovation;Sensors;Data visualization;Transforms,,,,,,,,14 Jan 2019,,,Wiley,Wiley Telecom eBook Chapters,
Virtualized Control Over Fog: Interplay Between Reliability and Latency,"Virtualized control, high latency, latency-to-reliability tradeoff, ","40, 12, 16,",H. Inaltekin; M. Gorlatova; M. Chiang,,IEEE Internet of Things Journal,16 Jan 2019,2018,5,6,5030,5045,"This paper introduces an analytical framework to investigate optimal design choices for the placement of virtual controllers along the cloud-to-things continuum. The main application scenarios include low-latency cyber-physical systems in which real-time control actions are required in response to the changes in states of an Internet of Things (IoT) node. In such cases, deploying controller software on a cloud server is often not tolerable due to delay from the network edge to the cloud. Hence, it is desirable to trade reliability with latency by moving controller logic closer to the network edge. Modeling the IoT node as a dynamical system that evolves linearly in time with quadratic penalty for state deviations, recursive expressions for the optimum control policy and the resulting minimum cost value are obtained by taking virtual fog controller reliability and response time latency into account. Our results indicate that latency is more critical than reliability in provisioning virtualized control services over fog endpoints, as it determines the swiftness of the fog control system as well as the timeliness of state measurements. Based on a drone trajectory tracking model, an extensive simulation study is also performed to illustrate the influence of reliability and latency on the control of autonomous vehicles over fog.",2327-4662,,10.1109/JIOT.2018.2881202,"Comcast Innovation Fund Research Grant; AWS Cloud Credits for Research; Microsoft(grant numbers:NSF CSR-1812797); National Science Foundation(grant numbers:1759652); NSF NeTS Award(grant numbers:1759656); Defense Advanced Research Projects Agency(grant numbers:HR001117C0052,HR001117C0048); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8533367,Control;distributed systems;fog computing;Internet of Things (IoT);latency;reliability,Edge computing;Cloud computing;Drones;Computer architecture;Software reliability;Control systems,,,,15,,77,IEEE,13 Nov 2018,,,IEEE,IEEE Journals,,
Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum,"Resource usage constraints, energy consumption constraints, financial costs constraints, heterogeneous computing resources, geographic distribution","17, 7, 20, 8, 3,",D. Rosendo; A. Costan; G. Antoniu; M. Simonin; J. -C. Lombardo; A. Joly; P. Valduriez,,2021 IEEE International Conference on Cluster Computing (CLUSTER),13 Oct 2021,2021,,,23,34,"In more and more application areas, we are witnessing the emergence of complex workflows that combine computing, analytics and learning. They often require a hybrid execution infrastructure with IoT devices interconnected to cloud/HPC systems (aka Computing Continuum). Such workflows are subject to complex constraints and requirements in terms of performance, resource usage, energy consumption and financial costs. This makes it challenging to optimize their configuration and deployment. We propose a methodology to support the optimization of real-life applications on the Edge-to-Cloud Continuum. We implement it as an extension of E2Clab, a previously proposed framework supporting the complete experimental cycle across the Edge-to-Cloud Continuum. Our approach relies on a rigorous analysis of possible configurations in a controlled testbed environment to understand their behaviour and related performance tradeoffs. We illustrate our methodology by optimizing Pl@ntNet, a world-wide plant identification application. Our methodology can be generalized to other applications in the Edge-to-Cloud Continuum.",2168-9253,978-1-7281-9666-4,10.1109/Cluster48925.2021.00043,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555989,Reproducibility;Methodology;Computing Continuum;Optimization,Performance evaluation;Instruction sets;Memory management;Graphics processing units;Production;Reproducibility of results;Time factors,cloud computing;computerised monitoring;Internet of Things;parallel processing;video signal processing,learning;aka Computing Continuum;complex constraints;real-life applications;Edge-to-Cloud Continuum;world-wide plant identification application;reproducible performance optimization;complex workflows,,1,,48,,13 Oct 2021,,,IEEE,IEEE Conferences,,
Orchestration of data-intensive pipeline in 5G-enabled Edge Continuum,"AI/ML-based services, security and privacy requirements, interoperability challenges, QoS awareness","6, 15, 10, 19,",M. Anisetti; F. Berto; M. Banzi,,2022 IEEE World Congress on Services (SERVICES),22 Aug 2022,2022,,,2,10,"Nowadays there is an increasing trend in the volume and velocity of data, typically consumed by data-intensive AI/ML-based services, requiring a larger diffusion of more effective Edge computing approaches. In addition, we are experiencing an increment of critical applications using an increasing volume of sensitive data and requiring advanced security and privacy protections. 5G Edge technology can foster a more diffused Edge computing adoption but several challenges in terms of interoperability. Handling data-intensive pipelines on the 5Genabled Edge continuum, considering specific QoS requirements including security and privacy, is still in its infancy. In this paper, we propose an initial solution for deploying a data-intensive pipeline in a 5G-enabled Edge continuum satisfying specific QoS requirements. Our approach is based on a QoS-aware meta orchestration modeling of a given pipeline and an orchestration builder generating deployable Edge-specific orchestrations. In this paper, we also present an initial walkthrough scenario in the context of a wet lab analysis pipeline to be deployed on the 5G-enabled Edge continuum.",2642-939X,978-1-6654-8131-1,10.1109/SERVICES55459.2022.00025,Università degli Studi di Milano; Regione Lombardia; Università degli Studi di Milano;,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9860308,5G;Edge;QoS;data-intensive pipeline;Orchestration;Cloud,Data privacy;5G mobile communication;Pipelines;Quality of service;Market research;Security;Interoperability,5G mobile communication;mobile computing;open systems;pipelines;quality of service,data-intensive AI-ML-based services;diffused edge computing approaches;5G edge technology;5G enabled edge continuum;deployable edge-specific orchestrations;wet lab analysis pipeline;QoS-aware meta orchestration modeling;handling data-intensive pipelines;privacy protections;5G-enabled Edge continuum;data-intensive pipeline,,,,26,IEEE,22 Aug 2022,,,IEEE,IEEE Conferences,,
A New Privacy-Preserving Framework based on Edge-Fog-Cloud Continuum for Load Forecasting,"Intelligent scheduling and planning, machine learning application, privacy concerns, bandwidth constraints","6, 15, 41,",S. Hou; H. Li; C. Yang; L. Wang,,2020 IEEE Wireless Communications and Networking Conference (WCNC),19 Jun 2020,2020,,,1,8,"As an essential part to intelligently fine-grained scheduling, planning and maintenance in smart grid and energy internet, short-term load forecasting makes great progress recently owing to the big data collected from smart meters and the leap forward in machine learning technologies. However, the centralized computing topology of classical electric information system, where individual electricity consumption data are frequently transmitted to the cloud center for load forecasting, tends to violate electric consumers’ privacy as well as to increase the pressure on network bandwidth. To tackle the tricky issues, we propose a privacy-preserving framework based on the edge-fog-cloud continuum for smart grid. Specifically, 1) we gravitate the training of load forecasting models and forecasting workloads to distributed smart meters so that consumers’ raw data are handled locally, and only the forecasting outputs that have been protected are reported to the cloud center via fog nodes; 2) we protect the local forecasting models that imply electricity features from model extraction attacks by model randomization; 3) we exploit a shuffle scheme among smart meters to protect the data ownership privacy, and utilize a re-encryption scheme to guarantee the forecasting data privacy. Finally, through comprehensive simulation and analysis, we validate our proposed privacy-preserving framework in terms of privacy protection, and computation and communication efficiency.",1558-2612,978-1-7281-3106-1,10.1109/WCNC45663.2020.9120680,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120680,,Data privacy;Cloud computing;Load forecasting;Computational modeling;Predictive models;Data models;Smart meters,Big Data;cryptography;data privacy;Internet;learning (artificial intelligence);load forecasting;power consumption;power engineering computing;smart meters;smart power grids,planning;maintenance;smart grid;energy internet;short-term load forecasting;big data;machine learning technologies;centralized computing topology;classical electric information system;individual electricity consumption data;cloud center;electric consumers;edge-fog-cloud continuum;forecasting workloads;distributed smart meters;fog nodes;local forecasting models;electricity features;model extraction attacks;model randomization;data ownership privacy;forecasting data privacy;privacy protection;privacy-preserving framework,,,,24,,19 Jun 2020,,,IEEE,IEEE Conferences,,
ICN-Fog: An Information-Centric Fog-to-Fog Architecture for Data Communications,"Mobility support, layered structure, distributed processing","13, 9, 4, ",D. Nguyen; Z. Shen; J. Jin; A. Tagami,,GLOBECOM 2017 - 2017 IEEE Global Communications Conference,15 Jan 2018,2017,,,1,6,"Fog computing is an emerging architecture for bringing processing, storage, and control from the Cloud closer to the Things/Users. Fog has mostly been studied in the vertical continuum between the Things/Users and the Cloud to provide resources traditionally existing in the remote Cloud to the applications. This paper introduces ICN-Fog, a novel horizontal Fog-to-Fog layer enabled by Information-Centric Networking. ICN-Fog enriches applications with horizontal data transfer in the Fog layer, distributed processing among Fog nodes, and built-in mobility support thanks to the smart connectionless name-based Fog-to-Fog data communications. We explain the rationale behind our design and demonstrate the advantages of the proposed Fog architecture through two representative case studies.",,978-1-5090-5019-2,10.1109/GLOCOM.2017.8254724,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254724,,Data communication;Computer architecture;Routing;Security;Cloud computing;Protocols;Edge computing,cloud computing;data communication;distributed processing,remote cloud;fog nodes;fog computing;information-centric fog-to-fog architecture;fog-to-fog data communications;horizontal data transfer;ICN-Fog enriches applications;Information-Centric Networking;emerging architecture,,7,,16,,15 Jan 2018,,,IEEE,IEEE Conferences,,
Leveraging the serverless paradigm for realizing machine learning pipelines across the edge-cloud continuum,"Serverlessness, machine learning usage, cost and resource usage constraints, scalability requirements","23, 6, 20, 17, 4,",E. Paraskevoulakou; D. Kyriazis,,"2021 24th Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN)",29 Mar 2021,2021,,,110,117,"The exceedingly exponential-growing data rate highlighted numerous requirements and several approaches have been released to maximize the added-value of cloud and edge resources. Whereas data scientists utilize algorithmic models in order to transform datasets and extract actionable knowledge, a key challenge is oriented towards abstracting the underline layers: the ones enabling the management of infrastructure resources and the ones responsible to provide frameworks and components as services. In this sense, the serverless approach features as the novel paradigm of new cloud-related technology, enabling the agile implementation of applications and services. The concept of Function as a Service (FaaS) is introduced as a revolutionary model that offers the means to exploit serverless offerings. Developers have the potential to design their applications with the necessary scalability in the form of nanoservices without addressing themselves the way the infrastructure resources should be deployed and managed. By abstracting away the underlying hardware allocations, the data scientist concentrates on the business logic and critical problems of Machine Learning (ML) algorithms. This paper introduces an approach to realize the provision of ML Functions as a Service (i.e., ML-FaaS), by exploiting the Apache OpenWhisk event-driven, distributed serverless platform. The presented approach tackles also composite services that consist of single ones i.e., workflows of ML tasks including processes such as aggregation, cleaning, feature extraction, and analytics; thus, reflecting the complete data path. We also illustrate the operation of the approach mentioned above and assess its performance and effectiveness exploiting a holistic, end-toend anti-fraud detection machine learning pipeline.",2472-8144,978-1-7281-7705-2,10.1109/ICIN51074.2021.9385525,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385525,machine learning;artificial intelligence;serverless;function as a service;cloud computing;edge computing,Pipelines;FAA;Feature extraction;Data models;Task analysis;Pipeline processing;Business,cloud computing;computer network management;data mining;feature extraction;fraud;learning (artificial intelligence);peer-to-peer computing;protocols;Web services,approach tackles;composite services;single ones;ML tasks;feature extraction;complete data path;end-toend anti-fraud detection machine;pipeline;serverless paradigm;edge-cloud continuum;data rate highlighted numerous requirements;added-value;edge resources;data scientists;algorithmic models;actionable knowledge;underline layers;infrastructure resources;serverless approach features;cloud-related technology;agile implementation;revolutionary model;serverless offerings;necessary scalability;underlying hardware allocations;data scientist concentrates;business logic;ML Functions;ML-FaaS;distributed serverless platform,,2,,31,,29 Mar 2021,,,IEEE,IEEE Conferences,,
SMURF: Efficient and Scalable Metadata Access for Distributed Applications from Edge to the Cloud,"Geo-distributed infrastructure, extremely high volume of generated data, metadata-intensive computing, scalability requirements","4, 11, 42,",B. Zhang; T. Kosar,,2019 IEEE International Conference on Edge Computing (EDGE),26 Aug 2019,2019,,,102,106,"In parallel with big data processing and analysis dominating the usage of distributed and cloud infrastructures, the demand for distributed metadata access and transfer has increased. In many application domains, the volume of data generated exceeds petabytes, while the corresponding metadata amounts to terabytes or even more. In this paper, we propose a novel solution for efficient and scalable metadata access for distributed applications across wide-area networks, dubbed SMURF. Our solution combines novel pipelining and concurrent transfer mechanisms with reliability, provides distributed continuum caching and prefetching strategies to sidestep fetching latency, and achieves scalable and high-performance metadata fetch/prefetch services in the cloud. We also study the phenomenon of semantic locality in real trace logs which is not well utilized in metadata access prediction. We implement our predictor based on this observation and compare it with three existing state-of-the-art prefetch schemes on Yahoo! Hadoop audit traces. By effectively caching and prefetching metadata based on the access patterns, our continuum caching and prefetching mechanism greatly improves local cache hit rate and reduces the average fetching latency. We replayed approximately 20 Million metadata access operations from real audit traces, in which our system achieved 80% accuracy during prefetch prediction and reduced the average fetch latency 50% compared to the state-of-the-art mechanisms.",,978-1-7281-2708-8,10.1109/EDGE.2019.00031,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812196,"Metadata access, semantic locality, prefetching, continuum caching, scalability, efficiency.",Prefetching;Metadata;Semantics;Servers;Wide area networks;Pipeline processing;Protocols,Big Data;cache storage;cloud computing;data handling;meta data;storage management,prefetching metadata;access patterns;continuum caching;prefetching mechanism;local cache hit rate;prefetch prediction;scalable metadata access;distributed applications;big data processing;distributed metadata access;dubbed SMURF;concurrent transfer mechanisms;prefetching strategies;metadata access prediction;metadata access operations;prefetch schemes,,2,,16,,26 Aug 2019,,,IEEE,IEEE Conferences,,
Leveraging Reinforcement Learning for online scheduling of real-time tasks in the Edge/Fog-to-Cloud computing continuum,"Low latency demands, high computing power demands, layered structure, heterogeneous devices, usage of reinforcement learning for scheduling","12, 32, 9, 8, 6,",G. P. Mattia; R. Beraldi,,2021 IEEE 20th International Symposium on Network Computing and Applications (NCA),31 Jan 2022,2021,,,1,9,"The computing continuum model is a widely ac-cepted and used approach that make possible the existence of applications that are very demanding in terms of low latency and high computing power. In this three-layered model, the Fog or Edge layer can be considered as the weak link in the chain, indeed the computing nodes whose compose it are generally heterogeneous and their uptime cannot be compared with the one offered by the Cloud. Taking into account these inexorable characteristics of the continuum, in this paper, we propose a Reinforcement Learning based scheduling algorithm that makes per-job request decisions (online scheduling) and that is able to maintain an acceptable performance specifically targeting real-time applications. Through a series of simulations and comparisons with other fixed scheduling strategies, we demonstrate how the algorithm is capable of deriving the best possible scheduling policy when Fog or Edge nodes have different speeds and can unpredictably fail.",2643-7929,978-1-6654-9550-9,10.1109/NCA53618.2021.9685413,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9685413,,Scheduling algorithms;Computational modeling;Reinforcement learning;Scheduling;Real-time systems;Task analysis;Low latency communication,cloud computing;distributed processing;reinforcement learning;telecommunication computing;telecommunication scheduling,real-time applications;fixed scheduling strategies;online scheduling;real-time tasks;continuum model;weak link;per-job request decisions;reinforcement learning;fog-to-cloud computing continuum,,,,16,IEEE,31 Jan 2022,,,IEEE,IEEE Conferences,,
Adaptive Resource Efficient Microservice Deployment in Cloud-Edge Continuum,"Service offloading, QoS control, contention- and load-awareness, dynamic deployment","14, 19, 26, 5,",K. Fu; W. Zhang; Q. Chen; D. Zeng; M. Guo,,IEEE Transactions on Parallel and Distributed Systems,8 Dec 2021,2022,33,8,1825,1840,"User-facing services are now evolving towards the microservice architecture where a service is built by connecting multiple microservice stages. Since the entire service is heavy, the microservice architecture shows the opportunity to only offload some microservice stages to the edge devices that are close to the end users. However, emerging techniques often result in the violation of Quality-of-Service (QoS) of microservice-based services in cloud-edge continuum, as they do not consider the communication overhead or the resource contention between microservices and external co-located tasks. We propose Nautilus, a runtime system that effectively deploys microservice-based user-facing services in cloud-edge continuum. Nautilus ensures the QoS of microservice-based user-facing services while minimizing the required computational resources, which is comprised of a communication-aware microservice mapper, a contention-aware resource manager and an IO-sensitive and load-aware microservice migration scheduler. The mapper divides the microservice graph into multiple partitions based on the communication overhead and maps the partitions to appropriate nodes. On each node, the resource manager determines the optimal resource allocation for its microservices based on reinforcement learning that may capture the complex contention behaviors. Once the microservices are suffered from external IO pressure, the IO-sensitive microservice scheduler migrates the critical one to idle nodes. Furthermore, when the load of microservices changes dynamically, the load-aware microservice scheduler migrates microservices from busy nodes to idle ones to ensure the QoS goal of the entire service. Our experimental results show that Nautilus can guarantee the required QoS target under external shared resources contention while the state-of-the-art suffers from QoS violations. Meanwhile, Nautilus reduces the computational resource usage by 23.9% and the network bandwidth usage by 53.4%, while achieving the required 99%-ile latency.",1558-2183,,10.1109/TPDS.2021.3128037,"National Key Research and Development Program of China(grant numbers:2018YFB1004800); National Natural Science Foundation of China(grant numbers:62022057,61832006,61632017,61872240); Open Research Projects of Zhejiang Lab(grant numbers:2021KE0AB02); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615028,Cloud-edge continuum;QoS;microservice resources management,Quality of service;Cloud computing;Task analysis;Resource management;Computer architecture;Runtime;Bandwidth,quality of service;radio networks;reinforcement learning;resource allocation;telecommunication computing;telecommunication network performance;telecommunication scheduling,adaptive resource efficient microservice deployment;cloud-edge continuum;microservice architecture;multiple microservice stages;entire service;quality-of-service;microservice-based services;communication overhead;resource contention;microservice-based user-facing services;required computational resources;communication-aware microservice mapper;contention-aware resource manager;load-aware microservice migration scheduler;microservice graph;IO-sensitive microservice scheduler;microservices changes;load-aware microservice scheduler;external shared resources contention;user-facing services;Nautilus;runtime system;optimal resource allocation;reinforcement learning;external IO pressure;computational resource usage;network bandwidth usage,,3,,57,IEEE,15 Nov 2021,,,IEEE,IEEE Journals,,
Robot Assistant in Management of Diabetes in Children Based on the Internet of Things,Not about ECC,,M. A. Al-Taee; W. Al-Nuaimy; Z. J. Muhsin; A. Al-Ataby,,IEEE Internet of Things Journal,20 May 2017,2017,4,2,437,445,"This paper presents a new eHealth platform incorporating humanoid robots to support an emerging multidimensional care approach for the treatment of diabetes. The architecture of the platform extends the Internet of Things to a Web-centric paradigm through utilizing existing Web standards to access and control objects of the physical layer. This incorporates capillary networks, each of which encompasses a set of medical sensors linked wirelessly to a humanoid robot linked (via the Internet) to a Web-centric disease management hub. This provides a set of services for both patients and their caregivers that support the full continuum of the multidimensional care approach of diabetes. The platform's software architecture pattern enables the development of various applications without knowing low-level details of the platform. This is achieved through unifying the access interface and mechanism of handling service requests through a layered approach based on object virtualization and automatic service delivery. A fully functional prototype is developed, and its end-to-end functionality and acceptability are tested successfully through a clinician-led pilot study, providing evidence that both patients and caregivers are receptive to the introduction of the proposed platform.",2327-4662,,10.1109/JIOT.2016.2623767,"7th European Community Framework Programme(grant numbers:275571); Kingston University London, U.K.; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7728003,Diabetes;eHealth;Internet of Things (IoT);multidimensional care;object virtualization;robot-assisted therapy,Diabetes;Robot sensing systems;Robot kinematics;Virtualization,health care;humanoid robots;Internet of Things;medical robotics,robot assistant;diabetes management;children;Internet of Things;eHealth platform;humanoid robots;diabetes treatment;multidimensional care approach;Web-centric paradigm;Web standards;capillary networks;layered approach;object virtualization;automatic service delivery,,40,,27,IEEE,1 Nov 2016,,,IEEE,IEEE Journals,,
FogPi: A Portable Fog Infrastructure through Raspberry Pis,"Time-sensitive applications, dynamic deployment, large data volumes, power and cost requirements","12, 5, 11, 20, 7,",C. Martín; D. R. Torres; M. Díaz; B. Rubio,,2020 9th Mediterranean Conference on Embedded Computing (MECO),7 Jul 2020,2020,,,1,3,"Nowadays, Fog computing is facing the requirements of time-sensitive applications in the IoT-cloud continuum. These requirements are decisive for mission-critical applications like structural health monitoring. In this paper, a portable Fog computing infrastructure, known as FogPi, is presented. This infrastructure has been designed around Raspberry Pi, which offers a low-cost and scalable solution for running containerized applications. FogPi allows the deployment, management, and orchestration of Docker containers and is especially suitable for environments where the limited Internet connection and reduced budgets limit the adoption of Fog and Edge deployments.",2637-9511,978-1-7281-6949-1,10.1109/MECO49872.2020.9134320,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134320,,Performance evaluation;Cloud computing;Three-dimensional displays;Modal analysis;Mission critical systems;Containers;Load management,cloud computing;microprocessor chips,FogPi;time-sensitive applications;IoT-cloud continuum;mission-critical applications;structural health monitoring;Raspberry Pi;portable fog computing infrastructure,,1,,5,,7 Jul 2020,,,IEEE,IEEE Conferences,,
AIDA-DB: A Data Management Architecture for the Edge and Cloud Continuum,"Large-scale distributed heterogeneous deployments, latency requirements, scalability requirements, fault tolerance requirements","8, 4, 12, 16,",N. Faria; D. Costa; J. Pereira; R. Vilaça; L. Ferreira; F. Coelho,,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),10 Feb 2022,2022,,,1,6,"There is an increasing demand for stateful edge computing for both complex Virtual Network Functions (VNFs) and application services in emerging 5G networks. Managing a mutable persistent state in the edge does however bring new architectural, performance, and dependability challenges. Not only it has to be integrated with existing cloud-based systems, but also cope with both operational and analytical workloads and be compatible with a variety of SQL and NoSQL database management systems. We address these challenges with AIDA-DB, a polyglot data management architecture for the edge and cloud continuum. It leverages recent development in distributed transaction processing for a reliable mutable state in operational workloads, with a flexible synchronization mechanism for efficient data collection in cloud-based analytical workloads.",2331-9860,978-1-6654-3161-3,10.1109/CCNC49033.2022.9700692,European Regional Development Fund; Foundation for Science and Technology;,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700692,Stateful edge;data management;polyglot processing;hybrid transactional analytical processing,Cloud computing;5G mobile communication;NoSQL databases;Computer architecture;Data collection;Synchronization;Reliability,5G mobile communication;cloud computing;data analysis;NoSQL databases;SQL;transaction processing;virtualisation,AIDA-DB;cloud continuum;stateful edge computing;application services;mutable persistent state;architectural performance;dependability challenges;cloud-based systems;operational workloads;polyglot data management architecture;reliable mutable state;efficient data collection;cloud-based analytical workloads;NoSQL database management systems;flexible synchronization mechanism;complex virtual network functions;VNF,,,,40,IEEE,10 Feb 2022,,,IEEE,IEEE Conferences,,
Delay Estimation in Fogs Based on Software-Defined Networking,"QoS management, delay sensitivity, high network traffic, real-time workloads","19, 12, 41, ",D. M. Casas-Velasco; W. F. Villota-Jacome; N. L. S. da Fonseca; O. M. Caicedo Rendon,,2019 IEEE Global Communications Conference (GLOBECOM),27 Feb 2020,2019,,,1,6,"Fog computing brings the advantages and power of cloud computing to the edge of the network. Software-Defined Networking (SDN) has been considered as a feasible solution to cope with the complexity of the orchestration of fog devices. Nevertheless, the use of an SDN controller introduces delays into the transport of packet flows in the fog layer, which may impact on the Quality of Service (QoS) of applications in the continuum IoT-Fog-Cloud. In this paper, we propose a regression model for predicting delay values in an SDN-based fog layer. To build up the regression model, we constructed a dataset, performed data cleaning, carried out feature selection, and applied different Machine Learning (ML) techniques. Our evaluation results reveal that the Random Forest (RF) technique overperforms Decision Tree (DT) and Neural Network (NN) techniques on predicting the delay in an SDN-based fog layer. Furthermore, the predicted delay values reinforce that a fog layer based on SDN can support different latency-sensitive applications.",2576-6813,978-1-7281-0962-6,10.1109/GLOBECOM38437.2019.9013980,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9013980,,Quality of service;Predictive models;Delay estimation;Data models;Cleaning;Feature extraction,cloud computing;data handling;decision trees;feature selection;Internet of Things;learning (artificial intelligence);neural nets;quality of service;random forests;regression analysis;software defined networking,delay estimation;software-defined networking;fog devices;SDN controller;delays;regression model;SDN-based fog layer;predicted delay values;fog computing;continuum IoT-fog-cloud;data cleaning;feature selection;machine learning techniques;ML techniques;random forest technique;RF technique;decision tree;neural network techniques;NN techniques;latency-sensitive applications,,,,33,,27 Feb 2020,,,IEEE,IEEE Conferences,,
"Cloud, Fog, or Edge: Where to Compute?","Heterogeneity, low latency, offloading, energy efficiency","8, 12, 14, 7,",D. Kimovski; R. Mathá; J. Hammer; N. Mehran; H. Hellwagner; R. Prodan,,IEEE Internet Computing,16 Aug 2021,2021,25,4,30,36,"The computing continuum extends the high-performance cloud data centers with energy-efficient and low-latency devices close to the data sources located at the edge of the network. However, the heterogeneity of the computing continuum raises multiple challenges related to application management. These include where to offload an application—from the cloud to the edge—to meet its computation and communication requirements. To support these decisions, we provide, in this article, a detailed performance and carbon footprint analysis of a selection of use case applications with complementary resource requirements across the computing continuum over a real-life evaluation testbed.",1941-0131,,10.1109/MIC.2021.3050613,Horizon 2020 Programme; Carinthian Agency for Investment Promotion and Public Shareholding;,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321525,Edge computing;Cloud computing;Benchmarking;Carbon footprint,Cloud computing;Encoding;Streaming media;Performance evaluation;Machine learning;Data centers;Computers,cloud computing;computer centres;energy conservation;virtual machines,data sources;computing continuum;application management;communication requirements;carbon footprint analysis;high-performance cloud data centers;low-latency devices,,14,,7,IEEE,13 Jan 2021,,,IEEE,IEEE Magazines,,
The Influence of Canyon Shadowing on Device-to-Device Connectivity in Urban Scenario,Not about ECC,,Q. le Gall; B. Błaszczyszyn; E. Cali; T. En-Najjary,,2019 IEEE Wireless Communications and Networking Conference (WCNC),31 Oct 2019,2019,,,1,7,"In this work, we use percolation theory to study the feasibility of large-scale connectivity of relay-augmented device-to-device (D2D) networks in an urban scenario featuring a haphazard system of streets and canyon shadowing allowing only for line-of-sight (LOS) communications in a finite range. We use a homogeneous Poisson-Voronoi tessellation (PVT) model of streets with homogeneous Poisson users (devices) on its edges and independent Bernoulli relays on the vertices. Using this model, we demonstrate the existence of a minimal threshold for relays below which large-scale connectivity of the network is not possible, regardless of all other network parameters. Through simulations, we estimate this threshold to 71.3%. Moreover, if the mean street length is not larger than some threshold (predicted to 74.3% of the communication range; which might be the case in a typical urban scenario) then any (whatever small) density of users can be compensated by equipping more crossroads with relays. Above this latter threshold, good connectivity requires some minimal density of users, compensated by the relays in a way we make explicit. The existence of the above regimes brings interesting qualitative arguments to the discussion on the possible D2D deployment scenarios.",1558-2612,978-1-5386-7646-2,10.1109/WCNC.2019.8885973,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8885973,Device-to-device networks;relays;connectivity;shadowing;continuum percolation;simulation,Relays;Device-to-device communication;Numerical models;Shadow mapping;Microsoft Windows;5G mobile communication;Interference,cellular radio;computational geometry;percolation;Poisson distribution;radio links;relay networks (telecommunication);stochastic processes,canyon shadowing;device-to-device connectivity;percolation theory;large-scale connectivity;relay-augmented device-to-device networks;haphazard system;line-of-sight communications;finite range;homogeneous Poisson-Voronoi tessellation model;homogeneous Poisson users;independent Bernoulli relays;minimal threshold;network parameters;mean street length;communication range;possible D2D deployment scenarios,,2,,34,,31 Oct 2019,,,IEEE,IEEE Conferences,,
Fundamental Challenges Toward Making the IoT a Reachable Reality: A Model-Centric Investigation,"Extremely large scale, decentralized computation, robustness, energy efficiency, hardware security","3, 4, 16, 7, 15,","Yuankun Xue, Ji Li, Shahin Nazarian, and Paul Bogdan",,,,2017,,,,,,,,10.1145/3001934,,,,,,,,,,,,,,,,,,
A Unified Cross-entropy Based Task Scheduling Algorithm for Heterogeneous Fog Networks,"Improving quality of service, low latency, energy consumption, heterogeneous nodes and networks","19, 12, 7, 8,","Zening Liu, Yang Yang, Ming-Tuo Zhou, and Ziqin Li",,,,2018,,,,,,,,10.1145/3277893.3277896,,,,,,,,,,,,,,,,,,
Fog Computing for the Internet of Things: A Survey,"Resource constraints, Security and Privacy challenges, orchestration challenges, mobility support, geographical distribution, heterogeneity, latency challenges, bandwidth consomption","17, 15, 5, 13, 3, 8, 12, 11,","Carlo Puliafito, Enzo Mingozzi, Francesco Longo, Antonio Puliafito, and Omer Rana",,,,2019,,,,,,,,10.1145/3301443,,,,,,,,,,,,,,,,,,
Non-functional requirements in the ELASTIC architecture,"distributed data sources, real-time support, energy efficiency, security challenges","3, 12, 7, 15,","Luis Nogueira, António Barros, Cristina Zubia, David Faura, Daniel Gracia Pérez, and Luis Miguel Pinho",,,,2020,,,,,,,,10.1145/3431235.3431243,,,,,,,,,,,,,,,,,,
Coral-Pie: A Geo-Distributed Edge-compute Solution for Space-Time Vehicle Tracking,"latency bounds, distributed architecture, self-healing, scalability","12, 4, 16,","Zhuangdi Xu, Harshil S Shah, and Umakishore Ramachandran",,,,2020,,,,,,,,10.1145/3423211.3425686,,,,,,,,,,,,,,,,,,
A Mathematical Model for Latency Constrained Self-Organizing Application Placement in the Edge,"Highly heterogeneous environment, adaptiveness, self-organization","8, 5, 1,","Matteo Mordacchini, Emanuele Carlini, and Patrizio Dazzi",,,,2022,,,,,,,,10.1145/3526059.3533620,,,,,,,,,,,,,,,,,,
FlexScience'22: 12th Workshop on AI and Scientific Computing at Scale using Flexible Computing Infrastructures,"Flexible infrastructure, AI and deep learning, flexible computing, real-time analysis, heterogeneity, on-demand resources","5, 6, 12, 8, 27","Alexandru Costan, Bogdan Nicolae, and Kento Sato",,,,2022,,,,,,,,10.1145/3502181.3535102,,,,,,,,,,,,,,,,,,